{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f586bab0-09e0-4cfb-bcea-695b0fb7cf80",
   "metadata": {},
   "source": [
    "## TF-IDF(Term Frequency-Inverse Document Frequency)\n",
    "\n",
    "### Model explanation\n",
    "\n",
    "一个容易想到的思路，就是找到出现次数最多的词。如果某个词很重要，它应该在这篇文章中多次出现。于是，我们进行\"词频\"（Term Frequency，缩写为TF）统计。以我们的小说为例，出现次数最多的词是----\"的\"、\"是\"、\"在\"----这一类最常用的词。它们叫做\"停用词\"（stop words），这类词对我们无用，需要过滤掉。假设我们把它们都过滤掉了，只考虑剩下的有实际意义的词。这样又会遇到了另一个问题，我们可能发现\"帅哥\"、\"美女\"这类的词出现的次数也是很高，可是这类词在所有书中都有很高的出现率，所以对我们也并不是十分有用，如果某个词比较少见，但是它在这篇文章中多次出现，那么它很可能就反映了这篇文章的特性，正是我们所需要的关键词。\n",
    "\n",
    "用统计学语言表达，就是在词频的基础上，要对每个词分配一个\"重要性\"权重。最常见的词（\"的\"、\"是\"、\"在\"）给予最小的权重，较常见的词（\"帅哥\"）给予较小的权重，较少见的词（\"魔幻\"、\"盛唐\"）给予较大的权重。这个权重叫做\"逆文档频率\"（Inverse Document Frequency，缩写为IDF），它的大小与一个词的常见程度成反比。知道了\"词频\"（TF）和\"逆文档频率\"（IDF）以后，将这两个值相乘，就得到了一个词的TF-IDF值。某个词对文章的重要性越高，它的TF-IDF值就越大。所以，排在最前面的几个词，就是这篇文章的关键词。\n",
    "\n",
    "It has many uses, most importantly in automated text analysis, and is very useful for scoring words in machine learning algorithm for NLP.\n",
    "\n",
    "### How is TF-IDF calculated?\n",
    "\n",
    "TF-IDF for a word in a document is calculated by multiplying two different metrics:\n",
    "\n",
    "- The **term frequency** of a word in a document. There are several ways of calculateing this frequency, with the simplest being a raw count of instances a word appears in a document. Then, there are ways to adjust the frequency by length of a document, or by the raw frequency of the most frequent word in a document.\n",
    "\n",
    "- The **inverse document frequency** of the word across a set of documents. This means, how common or rare a word is in the entire document set. The closer it is to 0, the more common a word is. The metric can be calculated by taking the total number of documents, dividing it by the number of documents that contain a word, and calculating the logarithm.\n",
    "\n",
    "Multiplying these two numbers results in the TF-IDF score of a word in a document. The higher the score, the more relevant that word is in that particular document.\n",
    "\n",
    "To put it in more formal mathematical terms, the TF-IDF score for the word $t$ in the document $d$ from the document set $D$ is calculated as follow:\n",
    "\n",
    "$$TF-IDF(t, d, D)=TF(t, d)\\cdot IDF(t, D)$$\n",
    "\n",
    "Where:\n",
    "\n",
    "$$TF(t, d)=log(1+freq(t, d))$$\n",
    "\n",
    "$$IDF(t, D)=log(\\frac{N}{count(d \\in D:t \\in d)})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5637fb33-3ff4-4ad2-a805-c105443272f3",
   "metadata": {},
   "source": [
    "### Why is TF-IDF used in Machine Learning?\n",
    "\n",
    "Machine Learning with natural language is faced with one major hurdle(栏) - its algorithms usually deal with numbers, and natural language is, well, text. So we need to transform that text into numbers, otherwise known as(也称为) text vectorization. It's a fundamental step in the process of machine learning for analyzing data, and different vectorization algorithms will drastically affect end results, so you need to choose one that will deliver the results you're hoping for.\n",
    "\n",
    "Once you've transformed words into numbers, in a way that's machine learning algorithms can understand, the TF-IDF score can be fed to algorithm such as Naive Bayes and Support Vector Machines, greatly improving the results of more basic methods like word counts.\n",
    "\n",
    "### Applications of TF-IDF\n",
    "\n",
    "- Information retrieval(信息检索)\n",
    "\n",
    "- Keyword Extraction\n",
    "\n",
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "818d7755-34a3-4213-9a07-51d68eb9acad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jieba import analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edd7289b-b62f-4571-ad70-6167f56f2711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jieba\n",
      "  Downloading jieba-0.42.1.tar.gz (19.2 MB)\n",
      "     |████████████████████████████████| 19.2 MB 15.6 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: jieba\n",
      "  Building wheel for jieba (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314477 sha256=1e7962fe1f31afb9a964b968c23898ff0b123bca2a12f1e986977aeec6cde7de\n",
      "  Stored in directory: /Users/leexuewei/Library/Caches/pip/wheels/ca/38/d8/dfdfe73bec1d12026b30cb7ce8da650f3f0ea2cf155ea018ae\n",
      "Successfully built jieba\n",
      "Installing collected packages: jieba\n",
      "Successfully installed jieba-0.42.1\n"
     ]
    }
   ],
   "source": [
    "!pip install jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "584ff20f-e4de-45f8-967b-1f991d4d9214",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /var/folders/k_/hsdmwgm9185b94nysv_v5_fc0000gp/T/jieba.cache\n",
      "Loading model cost 0.711 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['三生', '桃林', '忘不了', '三世', '十里', '蓁蓁', '玄幻', '伤眼', '生生世世', '杨幂', '赵又廷', '大剧', '互许', '中玄衣', '终能', '忘得', '情缘', '古装', '妖娆', '是否']\n"
     ]
    }
   ],
   "source": [
    "tfidf = analyse.extract_tags\n",
    "text = \"杨幂、赵又廷主演古装玄幻大剧原著小说，三生三世，她和他，是否注定背负一段纠缠的姻缘？三生三世，她和他，是否终能互许一个生生世世的承诺？\" \\\n",
    "       \"那一世，大荒之中一处荒山，成就她与他的初见。桃花灼灼，枝叶蓁蓁，妖娆伤眼。\" \\\n",
    "       \"记忆可以封存，可心有时也会背叛，忘得了前世情缘，忘不了桃林十里，亦忘不了十里桃林中玄衣的少年。\"\n",
    "keywords = tfidf(text)\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a636560-e095-4b0d-8672-58d483ec0afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['格斗', '王冠', '学长', '高中时代', '社的', '东大', '大学', '更有意义', '九牛二虎之力', '费尽', '击碎', '梦魇', '长空', '枯燥', '热血沸腾', '荆棘', '东江', '偶像', '元气', '满满的']\n"
     ]
    }
   ],
   "source": [
    "text = \"一个元气满满的格斗少年，费尽九牛二虎之力考入东江大学，只为挑战高中时代的学长偶像，亲手击碎高中三年的格斗梦魇。当他第一脚踏进东大长空格斗社的那天起，他才发现格斗王冠下的荆棘远远比夺得王冠要来的更有意义，枯燥的大学青春一样可以变得热血沸腾……\"\n",
    "keywords = tfidf(text)\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f2f4d78-8538-4a2a-9af3-e74ee831a97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['季晚', '弟弟', '心狠手毒', '四年', '郁东尧', '...', '亡者', '心上人', '名媛', '抄袭', '名门', '落魄', '车祸', '害死', '连环', '丑闻', '波澜', '天赋', '捆绑', '显赫']\n"
     ]
    }
   ],
   "source": [
    "text = \"她是落魄名媛季晚，亦是极具天赋的珠宝设计师；他是名门之后郁东尧，出身显赫。传闻他心狠手毒，亲手设计车祸，害死弟弟，又娶了弟弟的心上人季晚为妻。\"\\\n",
    "       \"四年前，一个事故、一场婚礼，将他与她的命运牢牢捆绑，她走不出去，他不曾归来。\"\\\n",
    "       \"四年后，当亡者与旧爱同时回归，掀起重重波澜，丑闻、抄袭门、连环车...\"\n",
    "keywords = tfidf(text)\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69bcd517-720b-4347-85b2-e2cdf052ad55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['奇案', '腥风血雨', '捕头', '沈锦文', '宁修', '灭门案', '女扮男装', '惊悚', '身负', '杀人案', '怀胎', '接踵而来', '谜团', '天翻地覆', '骇人听闻', '宫灯', '古国', '玉雕', '连环', '锦绣']\n"
     ]
    }
   ],
   "source": [
    "text = \"盛世锦绣，繁华大唐，一场无头连环女尸案掀起腥风血雨。\"\\\n",
    "       \"当女扮男装的捕头沈锦文，遇见身负重重谜团的宁修睿，她的世界便开始天翻地覆。\"\\\n",
    "       \"一桩桩奇案接踵而来，诡异惊悚的四方宫灯案，骇人听闻的密室灭门案，神秘离奇的南疆将士怀胎案，西域古国龟兹国进贡的九龙雕像玉雕杀人案\"\n",
    "keywords = tfidf(text)\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc5b767-9461-4552-af3c-2eff7b151c09",
   "metadata": {},
   "source": [
    "结果说明：\n",
    "\n",
    "1.由于用的jieba分词自带的语料库，所以对于小说语料不是很完整，过滤掉停用词，常见词等效果还能够提升，这个可以通过后期训练进行补充。\n",
    "\n",
    "2.输入数据仅为简介，所有可能有一些词可能拆分出来的并不是理想，如果实操需要采用小说内容。\n",
    "\n",
    "即使这样，从结果中还是可以看出重点词语大多数都被提取出来了，通过抽取的关键词结合人工提供的关键词，可以对小说进行更加准确的特征描述。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
