{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd908dda-a5dd-44ae-9e45-7ed585768c7b",
   "metadata": {},
   "source": [
    "## pack_padded_sequence和pad_packed_sequence\n",
    "\n",
    "当采用 RNN 训练序列样本数据时，会面临序列样本数据长短不一的情况。比如做 NLP 任务、语音处理任务时，每个句子或语音序列的长度经常是不相同。难道要一个序列一个序列的喂给网络进行训练吗？这显然是行不通的。\n",
    "\n",
    "为了更高效的进行 batch 处理，就需要对样本序列进行填充，保证各个样本长度相同，在 PyTorch 里面使用函数 pad_sequence 对序列进行填充。填充之后的样本序列，虽然长度相同了，但是序列里面可能填充了很多无效值 0 ，将填充值 0 喂给 RNN 进行 forward 计算，不仅浪费计算资源，最后得到的值可能还会存在误差。因此在将序列送给 RNN 进行处理之前，需要采用 pack_padded_sequence 进行压缩，压缩掉无效的填充值。序列经过 RNN 处理之后的输出仍然是压紧的序列，需要采用 pad_packed_sequence 把压紧的序列再填充回来，便于进行后续的处理。\n",
    "\n",
    "下面详细来说明每个函数的作用，以及每个函数之间的关系。\n",
    "\n",
    "### 一.pad_sequence\n",
    "\n",
    "**参数**\n",
    "\n",
    "* sequences:表示输入样本序列，为list类型，list中的元素为tensor类型。tensor的size为L\\* F。其中，L为单个序列的长度，F为序列中每个时间步(time step)特征的个数，根据任务的不同F的维度会有所不同。\n",
    "\n",
    "* batch_first:为True对应[batch_size, seq_len, feature];False对应[seq_len, batch_size, feature],从习惯上来将一般设置为True.\n",
    "\n",
    "* padding_value:默认为0，填充值\n",
    "\n",
    "#### 说明\n",
    "\n",
    "主要用来对样本进行填充，填充值一般为 0 。我们在训练网络时，一般会采用一个一个 mini-batch 的方式，将训练样本数据喂给网络。在 PyTorch 里面数据都是以 tensor 的形式存在，一个 mini-batch 实际上就是一个高维的 tensor ，每个序列数据的长度必须相同才能组成一个 tensor 。为了使网络可以处理 mini-batch 形式的数据，就必须对序列样本进行填充，保证一个 mini-batch 里面的数据长度是相同的。\n",
    "\n",
    "在 PyTorch 里面一般是使用 DataLoader 进行数据加载，返回 mini-batch 形式的数据，再将此数据喂给网络进行训练。我们一般会自定义一个 collate_fn 函数，完成对数据的填充。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fa950e48-96f8-4390-a271-953909a57b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pack_sequence, pad_packed_sequence\n",
    "\n",
    "class MyData(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "def collate_fn(data):\n",
    "    data.sort(key=lambda x: len(x), reverse=True)\n",
    "    data = pad_sequence(data, batch_first=True, padding_value=0)\n",
    "    return data\n",
    "\n",
    "a = torch.tensor([1,2,3,4])\n",
    "b = torch.tensor([5,6,7])\n",
    "c = torch.tensor([7,8])\n",
    "d = torch.tensor([9])\n",
    "train_x = [a, b, c, d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8dfe51f8-a27b-4b7e-9436-d0ed68bbf836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1, 2, 3, 4]), tensor([5, 6, 7]), tensor([7, 8]), tensor([9])]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "41631e9e-2f2b-476f-a056-f770d321cd14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.MyData at 0x7feb56122a60>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = MyData(train_x)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "844edc14-5855-4c85-b90e-49944ef0fcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(data, batch_size=2, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "81dadac5-3e9a-4b40-aa28-75919e2e1f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x = iter(data_loader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bc447c62-5283-42f2-bb78-3f8979e5dfe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 6, 7],\n",
       "        [7, 8, 0]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe102094-38eb-4f38-9ed0-504e24638678",
   "metadata": {},
   "source": [
    "从 batch_x 的值可以看出，第二行填充了一个 0 ，使其长度和第一行保持一致。\n",
    "\n",
    "需要说明的是，对于长度不同的序列，使用默认的 collate_fn 函数，不自定义 collate_fn 函数完成对序列的填充，上面的程序就会报错。\n",
    "\n",
    "### 二.pack_padded_sequence\n",
    "\n",
    "**参数**\n",
    "\n",
    "* input：经过 pad_sequence 处理之后的数据。\n",
    "\n",
    "* lengths：mini-batch中各个序列的实际长度。\n",
    "\n",
    "* batch_first：True 对应[batch_size, seq_len, feature];False对应[seq_len, batch_size, feature] 。\n",
    "\n",
    "* enforce_sorted：如果是 True ，则输入应该是按长度降序排序的序列。如果是 False ，会在函数内部进行排序。默认值为 True\n",
    "\n",
    "#### 说明\n",
    "\n",
    "pack意为压缩，因为数据在经过填充之后，会有很多冗余的padding_value,所以需要压缩一下。\n",
    "\n",
    "为什么要使用这个函数呢？\n",
    "\n",
    "RNN 读取数据的方式：网络每次吃进去一组同样时间步 （time step） 的数据，也就是 mini-batch 的所有样本中下标相同的数据，然后获得一个 mini-batch 的输出；再移到下一个时间步 （time step），再读入 mini-batch 中所有该时间步的数据，再输出；直到处理完所有的时间步数据。\n",
    "\n",
    "第一个时间步：\n",
    "\n",
    "第二个时间步：\n",
    "\n",
    "mini-batch 中的 0 只是用来做数据对齐的 padding_value ，如果进行 forward 计算时，把 padding_value 也考虑进去，可能会导致RNN通过了非常多无用的 padding_value，这样不仅浪费计算资源，最后得到的值可能还会存在误差。对于上面的序列 2 的数据，通过 RNN 网络：\n",
    "\n",
    "实际上从第 2 个时间步开始一直到最后的计算都是多余的，输入都是无效的 padding_value 而已。    \n",
    "从上面的分析可以看出，为了使 RNN 可以高效的读取数据进行训练，就需要在 pad 之后再使用 pack_padded_sequence 对数据进行处理。    \n",
    "需要注意的是，默认条件下，我们必须把输入数据按照序列长度从大到小排列后才能送入 pack_padded_sequence ，否则会报错。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ef26ef2a-77e9-4d3a-a1ac-59f077221633",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    data.sort(key=lambda x: len(x), reverse=True)\n",
    "    seq_len = [s.size(0) for s in data]  #获取数据真正长度\n",
    "    data = pad_sequence(data, batch_first=True)\n",
    "    data = pack_padded_sequence(data, seq_len, batch_first=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ee1f7b45-c0e9-48ad-93f8-d732f9f519f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(data, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
    "batch_x = iter(data_loader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "635f6723-883a-40bd-9f2d-6eb3cc44d5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([5, 9, 6, 7]), batch_sizes=tensor([2, 1, 1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93478336-0c55-45c5-8b9f-9dbff2d0d102",
   "metadata": {},
   "source": [
    "### 三.pack_sequence\n",
    "\n",
    "**参数**\n",
    "\n",
    "* sequences：输入样本序列，为 list 类型，list 中的元素为 tensor ；tensor 的 size 为 L * F，其中，L 为单个序列的长度，F 为序列中每个时间步（time step）特征的个数，根据任务的不同 F 的维度会有所不同。\n",
    "\n",
    "* enforce_sorted：如果是 True ，则输入应该是按长度降序排序的序列。如果是 False ，会在函数内部进行排序。默认值为 True 。\n",
    "\n",
    "#### 说明\n",
    "\n",
    "源码:\n",
    "```\n",
    "def pack_sequence(sequences, enforce_sorted=True): \n",
    "    lengths = torch.as_tensor([v.size(0) for v in sequences]) \n",
    "    return pack_padded_sequence(pad_sequence(sequences),lengths,enforce_sorted=enforce_sorted)\n",
    "```\n",
    "可以看出pack_sequence实际上是对pad_sequence和pack_padded_sequence操作的一个封装。通过一个函数完成了两步才能完成的工作。\n",
    "\n",
    "对前面collate_fn函数进一步修改："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "758ee828-1207-43a5-a5a3-34f963b84623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    data.sort(key=lambda x: len(x), reverse=True)\n",
    "   \n",
    "    data = pack_sequence(data)\n",
    "    #seq_len = [s.size(0) for s in data]\n",
    "    #data = pad_sequence(data, batch_first=True)    \n",
    "    #data = pack_padded_sequence(data, seq_len, batch_first=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "49ac67fc-b2ea-478b-8eeb-648b3b8c9aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([1, 7, 2, 8, 3, 4]), batch_sizes=tensor([2, 2, 1, 1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = DataLoader(data, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
    "batch_x = iter(data_loader).next()\n",
    "batch_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66c11e5-3cb7-4057-ae6f-53a27a3b838f",
   "metadata": {},
   "source": [
    "结果与之前的相同。\n",
    "\n",
    "### 四.pad_packed_sequence\n",
    "\n",
    "**参数**\n",
    "\n",
    "* sequences：PackedSequence 对象，将要被填充的 batch ；\n",
    "\n",
    "* batch_first：一般设置为 True，返回的数据格式为 [batch_size, seq_len, feature] ；\n",
    "\n",
    "* padding_value：填充值；\n",
    "\n",
    "* total_length：如果不是None，输出将被填充到长度：total_length。\n",
    "\n",
    "#### 说明\n",
    "\n",
    "如果在喂给网络数据的时候，用了 pack_sequence 进行打包，pytorch 的 RNN 也会把输出 out 打包成一个 PackedSequence 对象。这个函数实际上是 pack_padded_sequence 函数的逆向操作。就是把压紧的序列再填充回来。\n",
    "\n",
    "为啥要填充回来呢？我的理解是，在 collate_fn 函数里面通常也会调用 pad_sequence 对 label 进行填充，RNN 的输出结果为了和 label 对齐，需要将压紧的序列再填充回来，方便后续的计算。\n",
    "\n",
    "示例   \n",
    "需要说明的是，下面的程序中，为了产生符合 LSTM 输入格式 [batch_size, seq_len, feature] 的数据，使用了函数 unsqueeze 进行升维处理。其中， batch_size 是样本数，seq_len 是序列长度，feature 是特征数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "20cca15b-a052-4632-bbdc-c18328f410bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyData(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "a = torch.tensor([1,2,3,4])\n",
    "b = torch.tensor([5,6,7])\n",
    "c = torch.tensor([7,8])\n",
    "d = torch.tensor([9])\n",
    "train_x = [a, b, c, d]\n",
    "\n",
    "data = MyData(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "43f30bbb-fc03-4684-bd4a-4f9a7d4fcbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.sort(key=lambda x: len(x), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2b75255d-bc22-4236-9982-1bc831087950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1, 2, 3, 4]), tensor([5, 6, 7]), tensor([7, 8]), tensor([9])]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9936459d-f730-425b-b398-37f868e4ebfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = [s.size(0) for s in train_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "01f85d93-1d99-4677-8921-4efa82fffa94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 3, 2, 1]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2ee8a2f3-9bef-47cd-bf9a-4c675bd55906",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pad_sequence(train_x, batch_first=True).float()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6fdad96f-7363-42fb-bf4f-b22548838e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3., 4.],\n",
       "        [5., 6., 7., 0.],\n",
       "        [7., 8., 0., 0.],\n",
       "        [9., 0., 0., 0.]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ab9f8f29-e7e6-4c26-92ea-8d497dac7b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1fde7181-b799-42a2-85fc-60f8a5da724d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fc2f222a-aa3f-49c3-a7cc-1d045ec33cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.],\n",
       "         [2.],\n",
       "         [3.],\n",
       "         [4.]],\n",
       "\n",
       "        [[5.],\n",
       "         [6.],\n",
       "         [7.],\n",
       "         [0.]],\n",
       "\n",
       "        [[7.],\n",
       "         [8.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[9.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ee28943d-fd99-4b14-b5c6-4a73ebe98d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 1])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4e8ccc29-3b83-4a84-a9b2-108270a35e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[1.],\n",
       "        [5.],\n",
       "        [7.],\n",
       "        [9.],\n",
       "        [2.],\n",
       "        [6.],\n",
       "        [8.],\n",
       "        [3.],\n",
       "        [7.],\n",
       "        [4.]]), batch_sizes=tensor([4, 3, 2, 1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pack_padded_sequence(data, seq_len, batch_first=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2bbfee0f-c12c-4912-8c74-5d0a97ee4a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1, 2, 3, 4]), tensor([5, 6, 7]), tensor([7, 8]), tensor([9])]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5cfc0155-e213-4ce7-b1e8-d5b10cd9843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = MyData(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "408827da-eaea-41d2-b648-347e3735101d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([7, 9, 8]), batch_sizes=tensor([2, 1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = DataLoader(data, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
    "batch_x = iter(data_loader).next()\n",
    "batch_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0a2d2a87-ae4f-4098-86c6-bd00f0fa83db",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = torch.nn.LSTM(1, 4, 1, batch_first=True) # input_size,hidden_size,num_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1f215118-5136-4d12-80b0-79e31032dfeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(1, 4, batch_first=True)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "827c0a8b-4082-41a2-846c-4e71312dfff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = torch.rand(1, 2, 4).float()\n",
    "c0 = torch.rand(1, 2, 4).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e93a8bce-2941-4b27-a013-17be5c1e4e7f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input must have 2 dimensions, got 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-c6b4a98b0c52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    657\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0;31m# See torch/nn/modules/module.py::_forward_unimplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m         self.check_hidden_size(hidden[0], self.get_expected_hidden_size(input, batch_sizes),\n\u001b[1;32m    607\u001b[0m                                'Expected hidden[0] size {}, got {}')\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mexpected_input_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_input_dim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m    199\u001b[0m                 'input must have {} dimensions, got {}'.format(\n\u001b[1;32m    200\u001b[0m                     expected_input_dim, input.dim()))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input must have 2 dimensions, got 1"
     ]
    }
   ],
   "source": [
    "out, (h1, c1) = rnn(batch_x, (h0, c0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de42c6f-66d8-4b08-982d-dec09f99a350",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
