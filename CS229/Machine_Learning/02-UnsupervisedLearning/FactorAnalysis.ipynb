{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4655af02-34fe-41b4-96f2-f1cac108b5e3",
   "metadata": {},
   "source": [
    "## 1. 存在的问题\n",
    "\n",
    "在之前的推导中，我们通常假定拥有足够的数据来拟合模型，即 $m \\gg n$（样本量远大于维数）。但是如果维数远大于样本量，则难以对模型进行拟合。\n",
    "\n",
    "以简单的高斯分布为例，通过极大似然法可以得到：\n",
    "\n",
    "$$\\mu = \\frac{1}{m}\\sum_{i=1}^m x^{(i)}$$\n",
    "\n",
    "$$\\Sigma=\\frac{1}{m}\\sum_{i=1}^m(x^{(i)}-\\mu)(x^{(i)}-\\mu)^T$$\n",
    "\n",
    "可以发现 $\\Sigma$ 是奇异矩阵(行列式为0)，即特征值为 0，不满秩的矩阵，这意味着我们无法对 $\\Sigma$ 求逆，且 $1/\\Sigma^{1/2}=0$。因此我们无法写出该分布的概率密度函数，也就无法对其建模。我们可以将其理解为线性方程组求解，未知数的个数比方程数目多，因而无法完全求出所有未知数。\n",
    "\n",
    "我们可以通过一些方法解决这个问题，在接下来的几节中：我们首先会对协方差矩阵添加两种可能的限制，来帮助求解，但这些方法并不能完美解决问题；之后我们会介绍高斯分布的某些性质，并提出因子分析模型及其 EM 求解。\n",
    "\n",
    "## 2. 对协方差矩阵的限制\n",
    "\n",
    "对协方差矩阵的限制可以分为两种。第一种限制是假设矩阵为 **「对角矩阵」**，基于该假设，最大似然估计的结果为：\n",
    "\n",
    "$$\\Sigma_{jj}=\\frac{1}{m}\\sum_{i=1}^m(x_j^{(i)}-\\mu_j)^2$$\n",
    "\n",
    "* 对二维高斯分布来说，其概率密度在平面上的投影轮廓为椭圆。当协方差矩阵为对角矩阵时，椭圆的轴与坐标轴「平行」。\n",
    "\n",
    "第二种限制是进一步假设 **「对角线上的元素全部相同」**。此时 $\\Sigma=\\sigma^2 I$，其中最大似然估计表明：\n",
    "\n",
    "$$\\sigma^2=\\frac{1}{mn}\\sum_{j=1}^n\\sum_{i=1}^m(x_j^{(i)}-\\mu_j)^2$$\n",
    "\n",
    "此时投影轮廓为圆（高维情况下为球面或超球面）。\n",
    "\n",
    "在没有限制的情况下，我们需要 $m>n+1$ 来保证 $\\Sigma$ 的最大似然估计不是奇异矩阵。而在上述两个限制中的任意一个下，我们只需要 $m\\geq 2$ 来保证非奇异。但是在上述限制下，我们会丢失部分特征项之间的相互联系。\n",
    "\n",
    "接下来我们将介绍 **「因子分析」** 模型，其能够发现数据间的某些关联，并且不用去拟合整个协方差矩阵（实际上因子模型的求解也要求样本量一定程度上超过变量维数以保证效果）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3039dc48-3360-4d3f-a079-10a52acddebf",
   "metadata": {},
   "source": [
    "## 3. 高斯分布的边缘和条件分布\n",
    "\n",
    "在介绍因子分析前，我们先介绍联合多元高斯分布的边缘分布和条件分布。假定我们有一个由两个变量组合而成的随机变量：\n",
    "\n",
    "$$x=\\begin{bmatrix}\n",
    "   x_1  \\\\\n",
    "   x_2  \n",
    "  \\end{bmatrix}$$\n",
    "\n",
    "其中 $x_1\\in \\mathbb R^r,x_2\\in \\mathbb R^s$，因此 $x\\in \\mathbb R^{r+s}$。\n",
    "\n",
    "假定 $x \\sim \\mathcal{N}(\\mu,\\Sigma)$，其中\n",
    "\n",
    "$$\\mu=\\begin{bmatrix}\n",
    "   \\mu_1  \\\\\n",
    "   \\mu_2  \n",
    "  \\end{bmatrix},\\Sigma=\\begin{bmatrix}\n",
    "   \\Sigma_{11} & \\Sigma_{12}  \\\\\n",
    "   \\Sigma_{21} & \\Sigma_{22}  \n",
    "  \\end{bmatrix}$$\n",
    "\n",
    "这里 $\\mu_1\\in \\mathbb{R}^r,\\mu_2\\in \\mathbb{R}^s,\\Sigma_{11}\\in \\mathbb{R}^{r\\times r},\\Sigma_{12}\\in \\mathbb{R}^{r\\times s}$，以此类推。因为协方差矩阵 $\\Sigma$ 是对称的，所以 $\\Sigma_{12}=\\Sigma_{21}^T$。\n",
    "\n",
    "基于上述定义，我们可以求出 $x_1$ 的 **「边缘分布」**：\n",
    "\n",
    "$$E[x_1]=\\mu_1$$\n",
    "\n",
    "$$\\text{Cov}(x_1)=E[(x_1-\\mu_1)(x_1-\\mu_1)^T]=\\Sigma_{11}$$\n",
    "\n",
    "关于协方差公式的证明如下：\n",
    "\n",
    "$$\\text{Cov}(x)=\\Sigma=\\begin{bmatrix}\n",
    "   \\Sigma_{11} & \\Sigma_{12}  \\\\\n",
    "   \\Sigma_{21} & \\Sigma_{22}  \n",
    "  \\end{bmatrix}$$\n",
    "  \n",
    "$$=E[(x-\\mu)(x-\\mu)^T]$$\n",
    "\n",
    "$$=E\\begin{bmatrix}\n",
    "\\begin{pmatrix}x_1-\\mu_1 \\\\ x_2-\\mu_2 \\\\ \\end{pmatrix} & \\begin{pmatrix}x_1-\\mu_1 \\\\ x_2-\\mu_2\\\\ \\end{pmatrix}^T\\\\  \n",
    "\\end{bmatrix}$$\n",
    "\n",
    "$$=E\\begin{bmatrix}\n",
    "(x_1-\\mu_1)(x_1-\\mu_1)^T & (x_1-\\mu_1)(x_2-\\mu_2)^T \\\\ \n",
    "(x_2-\\mu_2)(x_1-\\mu_1)^T & (x_2-\\mu_2)(x_2-\\mu_2)^T\\\\ \n",
    "\\end{bmatrix}$$\n",
    "\n",
    "因为边缘分布本身也是高斯分布，所以有：\n",
    "\n",
    "$$x_1 \\sim \\mathcal{N}(\\mu_1,\\Sigma_{11})$$\n",
    "\n",
    "类似地，我们可以推导出条件分布 $x_1|x_2\\sim \\mathcal{N}(\\mu_{1|2},\\Sigma_{1|2})$，其中：\n",
    "\n",
    "$$\\mu_{1|2}=\\mu_1+\\Sigma_{12}\\Sigma_{22}^{-1}(x_2-\\mu_2)\\tag{1}$$\n",
    "\n",
    "$$\\Sigma_{1|2}=\\Sigma_{11}-\\Sigma_{12}\\Sigma_{22}^{-1}\\Sigma_{21}\\tag{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2715c449-7b2c-4ad7-b969-4ca967eecb9d",
   "metadata": {},
   "source": [
    "## 4. 因子分析模型\n",
    "\n",
    "### 4.1 模型的提出\n",
    "\n",
    "因子分析模型是指通过少数几个潜在变量（因子）来表示原始数据，以此发现特征项之间的相互联系，探求原始数据的基本结构，其本质是一种 **「降维」** 方法。\n",
    "\n",
    "在因子模型中，我们提出如下的联合分布 $(x,z)$：\n",
    "\n",
    "$$z \\sim \\mathcal{N}(0,I)$$\n",
    "\n",
    "$$x|z \\sim \\mathcal{N}(\\mu+\\Lambda z,\\Psi)$$\n",
    "\n",
    "其中 $z\\in \\mathbb{R}^k$ 是潜在随机变量，$k$ 应该小于 $n$。模型的参数包括：\n",
    "\n",
    "* 向量 $\\mu \\in \\mathbb{R}^n$\n",
    "\n",
    "* 矩阵 $\\Lambda \\in \\mathbb{R}^{n\\times k}$\n",
    "\n",
    "* 对角矩阵 $\\Psi \\in \\mathbb{R}^{n\\times n}$\n",
    "\n",
    "我们可以想象 $x^{(i)}$ 是通过对 $k$ 维多元高斯分布 $z^{(i)}$ 进行采样生成的。首先通过计算 $\\mu+\\Lambda z^{(i)}$ 将其映射至 $k$ 维仿射空间 $\\mathbb{R}^n$，然后通过加上协方差噪声 $\\Psi$ 生成 $x^{(i)}$。\n",
    "\n",
    "我们也可以将上述模型表示为如下形式：\n",
    "\n",
    "$$z\\sim \\mathcal{N}(0,I)$$\n",
    "\n",
    "$$\\epsilon \\sim \\mathcal{N}(0,\\Psi)$$\n",
    "\n",
    "$$x=\\mu +\\Lambda z + \\epsilon$$\n",
    "\n",
    "其中 $\\epsilon$ 和 $z$ 是独立的。\n",
    "\n",
    "### 4.2 模型的求解\n",
    "\n",
    "我们的随机变量 $z$ 和 $x$ 有如下的联合高斯分布：\n",
    "\n",
    "$$\\begin{bmatrix}z \\\\ x\\\\ \\end{bmatrix} \\sim \\mathcal{N}(\\mu_{zx},\\Sigma)$$\n",
    "\n",
    "下面将分别求解 $\\mu_{zx}$ 和 $\\Sigma$。根据 $z\\sim \\mathcal{N}(0,I)$，我们有 $E[z]=0$，而\n",
    "\n",
    "$$E[x]=E[\\mu+\\Lambda z+\\epsilon]=\\mu+\\Lambda E[z]+E[\\epsilon]=\\mu$$\n",
    "\n",
    "将两者结合在一起，得到：\n",
    "\n",
    "$$\\mu_{zx}=\\begin{bmatrix}\\vec{0} \\\\ \\mu\\\\ \\end{bmatrix}$$\n",
    "\n",
    "为了求解 $\\Sigma$，我们需要计算 $\\Sigma_{zz}$（矩阵左上角）、$\\Sigma_{zx}$（矩阵右上角）和 $\\Sigma_{xx}$（矩阵右下角），矩阵左下角与右上角对称，计算其一即可。\n",
    "\n",
    "由于 $z \\sim \\mathcal{N}(0,I)$，根据之前提出的边缘分布性质，有 $\\Sigma_{zz}=\\text{Cov}(z)=I$\n",
    "\n",
    "$\\Sigma_{zx}$ 的求解如下：\n",
    "\n",
    "$$\\Sigma_{zx}=E[(z-E[z])(x-E[x])^T]$$\n",
    "\n",
    "$$=E[z(\\mu+\\Lambda z+\\epsilon-\\mu)^T]$$\n",
    "\n",
    "$$=E[zz^T]\\Lambda^T+E[z\\epsilon^T]=\\Lambda^T$$\n",
    "\n",
    "最后一步的推导使用了 $E[zz^T]=\\text{Cov}(z)+(E[z])^2=\\text{Cov}(z)$ 以及 $E[z\\epsilon^T]=E[z]E[\\epsilon^T]=0$（因为 $z$ 和 $\\epsilon$ 相互独立）。\n",
    "\n",
    "类似地，$\\Sigma_{xx}$ 的求解如下：\n",
    "\n",
    "$$\\Sigma_{xx}=E[(x-E[x])(x-E[x])^T]$$\n",
    "\n",
    "$$=E[(\\mu+\\Lambda z+\\epsilon-\\mu)(\\mu+\\Lambda z+\\epsilon-\\mu)^T]$$\n",
    "\n",
    "$$=\\Lambda E[zz^T]\\Lambda^T+E[\\epsilon \\epsilon^T]=\\Lambda \\Lambda^T+\\Psi$$\n",
    "\n",
    "综上所述，得：\n",
    "\n",
    "$$\\begin{bmatrix}\n",
    "z \\\\ \n",
    "x \\\\ \n",
    "\\end{bmatrix} \\sim \\mathcal{N}(\\begin{bmatrix}\n",
    "\\vec{0} \\\\ \n",
    "\\mu \\\\ \n",
    "\\end{bmatrix},\\begin{bmatrix}\n",
    "I & \\Lambda^T \\\\ \n",
    "\\Lambda & \\Lambda \\Lambda^T+\\Psi \\\\ \n",
    "\\end{bmatrix})\\tag{3}$$\n",
    "\n",
    "因此，$x$ 的边缘分布为 $x \\sim \\mathcal{N}(\\mu,\\Lambda \\Lambda^T+\\Psi)$。\n",
    "\n",
    "给定一个训练集 $\\{x^{(i)};i=1,...,m\\}$，我们可以得出如下的对数似然函数：\n",
    "\n",
    "$$\\ell(\\mu,\\Lambda,\\Psi)=\\sum_{i=1}^m \\text{log}p(x^{(i)};\\mu,\\Lambda,\\Psi)$$\n",
    "\n",
    "$$=\\text{log}\\prod_{i=1}^m \\frac{1}{(2\\pi)^{n/2}|\\Lambda \\Lambda^T+\\Psi|^{1/2}}\\text{exp}\\Big(-\\frac{1}{2}(x^{(i)}-\\mu)^T(\\Lambda \\Lambda^T+\\Psi)^{-1}(x^{(i)}-\\mu)\\Big)$$\n",
    "\n",
    "对该函数进行最大化估计是难以求出闭合解的，我们将使用 EM 算法来求解该问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c8eb50-7e78-484b-b928-ca6dd25ba492",
   "metadata": {},
   "source": [
    "## 5. 因子分析模型的 EM 求解\n",
    "\n",
    "### 5.1 E-step\n",
    "\n",
    "在 E-step 中，我们需要计算 $Q_i(z^{(i)})=p(z^{(i)}|x^{(i)};\\mu,\\Lambda,\\Psi)$。\n",
    "\n",
    "将 $(3)$ 式代入之前推导出的条件分布公式 $(1)$ 和 $(2)$，可以得出 $z^{(i)}|x^{(i)};\\mu,\\Lambda,\\Psi \\sim \\mathcal{N}(\\mu_{z^{(i)}|x^{(i)}},\\Sigma_{z^{(i)}|x^{(i)}})$ ，其中：\n",
    "\n",
    "$$\\mu_{z^{(i)}|x^{(i)}}=\\Lambda^T(\\Lambda \\Lambda^T+\\Psi)^{-1}(x^{(i)}-\\mu),$$\n",
    "\n",
    "$$\\Sigma_{z^{(i)}|x^{(i)}}=I-\\Lambda^T(\\Lambda \\Lambda^T +\\Psi)^{-1}\\Lambda$$\n",
    "\n",
    "因此，基于上述定义，我们有：\n",
    "\n",
    "$$Q_i(z^{(i)})=\\frac{1}{(2\\pi)^{k/2}|\\Sigma_{z^{(i)}|x^{(i)}}|^{1/2}}\\text{exp}\\Big(-\\frac{1}{2}(z^{(i)}-\\mu_{z^{(i)}|x^{(i)}})^T(\\Sigma_{z^{(i)}|x^{(i)}})^{-1}(z^{(i)}-\\mu_{z^{(i)}|x^{(i)}})\\Big)$$\n",
    "\n",
    "### 5.2 M-step\n",
    "\n",
    "在 M-step 中，我们需要最大化：\n",
    "\n",
    "$$\\sum_{i=1}^m \\int_{z^{(i)}}Q_i(z^{(i)})\\text{log}\\frac{p(x^{(i)},z^{(i)};\\mu,\\Lambda,\\Psi)}{Q_i(z^{(i)})}dz^{(i)}\\tag{4}$$\n",
    "\n",
    "下面介绍关于参数 $\\Lambda$ 的优化方法，其他两个参数的推导省略。\n",
    "\n",
    "我们可以将 $(4)$ 式简化为：\n",
    "\n",
    "$$\\sum_{i=1}^m \\int_{z^{(i)}}Q_i(z^{(i)})[\\text{log}p(x^{(i)}|z^{(i)};\\mu,\\Lambda,\\Psi)+\\text{log}p(z^{(i)})-\\text{log}Q_i(z^{(i)})]dz^{(i)}\\tag{5}$$\n",
    "\n",
    "$$\\sum_{i=1}^m E_{z^{(i)}\\sim Q_i}[\\text{log}p(x^{(i)}|z^{(i)};\\mu,\\Lambda,\\Psi)+\\text{log}p(z^{(i)})-\\text{log}Q_i(z^{(i)})]\\tag{6}$$\n",
    "\n",
    "因为 $z\\sim \\mathcal{N}(0,I)$，所以 $\\text{log}p(z^{(i)})$ 与 $\\Lambda$ 无关。$\\text{log}Q_i(z^{(i)})$ 中的参数来自上一次迭代，与本次迭代中的参数无关。\n",
    "\n",
    "综上所述，我们需要优化的函数为：\n",
    "\n",
    "$$\\sum_{i=1}^m E_{z^{(i)}\\sim Q_i}[\\text{log}p(x^{(i)}|z^{(i)};\\mu,\\Lambda,\\Psi)]$$\n",
    "\n",
    "$$=\\sum_{i=1}^m E\\Big[\\text{log}\\frac{1}{(2\\pi)^{n/2}|\\Psi|^{1/2}}\\text{exp}\\Big(-\\frac{1}{2}(x^{(i)}-\\mu-\\Lambda z^{(i)})^T\\Psi^{-1}(x^{(i)}-\\mu-\\Lambda z^{(i)})\\Big)\\Big]$$\n",
    "\n",
    "$$=\\sum_{i=1}^m E\\Big[-\\frac{1}{2}\\text{log}|\\Psi|-\\frac{n}{2}\\text{log}(2\\pi)-\\frac{1}{2}(x^{(i)}-\\mu-\\Lambda z^{(i)})^T\\Psi^{-1}(x^{(i)}-\\mu-\\Lambda z^{(i)})\\Big]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aac05a1-c478-4f09-a06a-4e122a90ff99",
   "metadata": {},
   "source": [
    "具体的求导过程如下（上式只有最后一项与参数相关）：\n",
    "\n",
    "$$\\triangledown_{\\Lambda}\\sum_{i=1}^m -E\\Big[\\frac{1}{2}(x^{(i)}-\\mu-\\Lambda z^{(i)})^T\\Psi^{-1}(x^{(i)}-\\mu-\\Lambda z^{(i)})\\Big]$$\n",
    "\n",
    "$$=\\sum_{i=1}^m\\triangledown_{\\Lambda} E \\Big[-\\text{tr}\\frac{1}{2} {z^{(i)}}^T \\Lambda^T \\Psi^{-1} \\Lambda z^{(i)}+\\text{tr}{z^{(i)}}^T \\Lambda^T \\Psi^{-1}(x^{(i)}-\\mu)\\Big]$$\n",
    "\n",
    "$$=\\sum_{i=1}^m\\triangledown_{\\Lambda} E \\Big[-\\text{tr}\\frac{1}{2} \\Lambda^T \\Psi^{-1} \\Lambda z^{(i)}{z^{(i)}}^T+\\text{tr}\\Lambda^T \\Psi^{-1}(x^{(i)}-\\mu){z^{(i)}}^T \\Big]$$\n",
    "\n",
    "$$=\\sum_{i=1}^m E\\Big[-\\Psi^{-1}\\Lambda z^{(i)}{z^{(i)}}^T +\\Psi^{-1}(x^{(i)}-\\mu){z^{(i)}}^T\\Big]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb1b5c5-0224-41da-a9d4-6bf0b5bc100e",
   "metadata": {},
   "source": [
    "第一步首先将连乘打开，然后由于结果均为实数，所以用迹替换（$\\text{tr}a=a$）；第二步使用迹的性质 $\\text{tr}AB=\\text{tr}BA$；第三步使用了迹的多条性质：\n",
    "\n",
    "$$\\triangledown_{A^T}f(A)=(\\triangledown_A f(A))^T$$\n",
    "\n",
    "$$\\triangledown_{A^T}\\text{tr}ABA^T C=B^T A^T C^T + BA^T C$$\n",
    "\n",
    "$$\\triangledown_A \\text{tr} AB=B^T$$\n",
    "\n",
    "将求导结果设为 0 并简化，得到：\n",
    "\n",
    "$$\\sum_{i=1}^m \\Lambda E_{z^{(i)}\\sim Q_i}\\Big[ z^{(i)}{z^{(i)}}^T\\Big]=\\sum_{i=1}^m (x^{(i)}-\\mu)E_{z^{(i)}\\sim Q_i}\\Big[{z^{(i)}}^T \\Big]$$\n",
    "\n",
    "因此，我们可以解得：\n",
    "\n",
    "$$\\Lambda=\\Big(\\sum_{i=1}^m (x^{(i)}-\\mu)E_{z^{(i)}\\sim Q_i}\\Big[{z^{(i)}}^T \\Big]\\Big)\\Big(\\sum_{i=1}^m E_{z^{(i)}\\sim Q_i}\\Big[ z^{(i)}{z^{(i)}}^T\\Big]\\Big)^{-1}\\tag{7}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3979b9e-e228-4f86-a2c4-65fa52c13233",
   "metadata": {},
   "source": [
    "该结果与线性回归中正规方程的解在形式上类似，因为二者都是在寻找两个变量之间的线性关系。\n",
    "\n",
    "对 $(7)$ 式中的期望值进行求解，得到：\n",
    "\n",
    "$$E_{z^{(i)}\\sim Q_i}\\Big[{z^{(i)}}^T \\Big]=\\mu_{z^{(i)}|x^{(i)}}^T$$\n",
    "\n",
    "$$E_{z^{(i)}\\sim Q_i}\\Big[z^{(i)}{z^{(i)}}^T \\Big]=\\mu_{z^{(i)}|x^{(i)}}\\mu_{z^{(i)}|x^{(i)}}^T+\\Sigma_{z^{(i)}|x^{(i)}}$$\n",
    "\n",
    "第二项的求解源于公式 $E(YY^T)=E(Y)E(Y^T)+\\text{Cov}(Y)$，协方差项在求解中容易被忽略，需要注意。\n",
    "\n",
    "综上所述，可以得到 $\\Lambda$ 在 M-step 的更新公式为：\n",
    "\n",
    "$$\\Lambda=\\Big(\\sum_{i=1}^m (x^{(i)}-\\mu)\\mu_{z^{(i)}|x^{(i)}}^T\\Big)\\Big(\\sum_{i=1}^m \\mu_{z^{(i)}|x^{(i)}}\\mu_{z^{(i)}|x^{(i)}}^T+\\Sigma_{z^{(i)}|x^{(i)}}\\Big)^{-1}\\tag{8}$$\n",
    "\n",
    "M-step 的其他两个参数的更新公式如下：\n",
    "\n",
    "$$\\mu=\\frac{1}{m}\\sum_{i=1}^m x^{(i)}$$\n",
    "\n",
    "该公式与参数无关，因此只需要计算一次即可。\n",
    "\n",
    "$$\\Phi=\\frac{1}{m}\\sum_{i=1}^m x^{(i)}{x^{(i)}}^T-x^{(i)}\\mu_{z^{(i)}|x^{(i)}}^T\\Lambda^T-\\Lambda \\mu_{z^{(i)}|x^{(i)}} {x^{(i)}}^T + \\Lambda(\\mu_{z^{(i)}|x^{(i)}} \\mu_{z^{(i)}|x^{(i)}}^T+\\Sigma_{z^{(i)}|x^{(i)}})\\Lambda^T$$\n",
    "\n",
    "只取 $\\Psi$ 的对角元素组成 $\\Phi$（即令 $\\Psi_{ii}=\\Phi_{ii}$）。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
