{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基本配置　　\n",
    "### 导入包和版本查询"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.0\n",
      "10.1\n",
      "7603\n",
      "GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "import PIL\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.backends.cudnn.version())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 更新PyTorch\n",
    "\n",
    "`PyTorch`将被安装在`anaconda3/lib/python3.7/site-packages/torch/`目录下  \n",
    "`conda update pytorch torchvision -c pytorch`  \n",
    "\n",
    "### 固定随机种子\n",
    "\n",
    "`torch.manual_seed(0)`\n",
    "\n",
    "`torch.cuda.manual_seed_all(0)`  \n",
    "\n",
    "### 指定程序运行在特定GPU卡上\n",
    "\n",
    "在命令行指定环境变量\n",
    "\n",
    "`CUDA_VISIBLE_DEVICES=0,1 python train.py`\n",
    "或在代码中指定\n",
    "\n",
    "`os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'`   \n",
    "\n",
    "### 判断是否有CUDA支持\n",
    "\n",
    "`torch.cuda.is_available()`\n",
    "\n",
    "### 设置为cuDNN benchmark模式\n",
    "\n",
    "`Benchmark`模式会提升计算速度，但是由于计算中有随机性，每次网络前馈结果略有差异。\n",
    "\n",
    "`torch.backends.cudnn.benchmark = True`\n",
    "如果想要避免这种结果波动，设置\n",
    "\n",
    "`torch.backends.cudnn.deterministic = True`\n",
    "\n",
    "### 清除GPU存储\n",
    "\n",
    "有时`Control-C`中止运行后`GPU`存储没有及时释放，需要手动清空。在`PyTorch`内部可以\n",
    "\n",
    "`torch.cuda.empty_cache()`  \n",
    "或在命令行可以先使用`ps`找到程序的`PID`，再使用`kill`结束该进程\n",
    "\n",
    "`ps aux | grep python`   \n",
    "`ps aux:see every process on the system`  \n",
    "`kill -9 [pid]`\n",
    "或者直接重置没有被清空的`GPU`\n",
    "\n",
    "`nvidia-smi --gpu-reset -i [gpu_id]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 张量(Tensor)处理  \n",
    "\n",
    "`torch.is_tensor(obj)`  \n",
    "`torch.is_storage(obj)`:Returns True if obj is a PyTorch storage object.  \n",
    "`torch.is_complex(input), input:Tensor`  \n",
    "`torch.is_floating_point(input), input:Tensor`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.tensor([1.2, 3]).dtype # initial default for floating point is torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1.2, 3]).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.get_default_dtype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.FloatTensor)  # changed to torch.float32, the dtype for torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.get_default_dtype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.DoubleTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1.2, 3]).dtype "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.numel(input)--> int, input:Tensor`  \n",
    "\n",
    "Returns the total number of elements in the input tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(1, 2, 3, 4, 5)\n",
    "torch.numel(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.zeros(4,4)\n",
    "torch.numel(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "# 类型转换\n",
    "tensor = tensor.cuda()\n",
    "tensor = tensor.cpu()\n",
    "print(tensor.dtype)\n",
    "tensor = tensor.long()\n",
    "print(tensor.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.set_printoptions(precision=None, threshold=None, edgeitems=None, linewidth=None, profile=None)`\n",
    "\n",
    "`precision`是每一个元素的输出精度，默认是八位；  \n",
    "`threshold`是输出时的阈值，当`tensor`中元素的个数大于该值时，进行缩略输出，默认时1000；  \n",
    "`edgeitems`是输出的维度，默认是3；  \n",
    "`linewidth`字面意思，每一行输出的长度；  \n",
    "`profile=None`，修正默认设置（不太懂，感兴趣的可以试试)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8221, -1.8515, -0.3171],\n",
       "        [ 0.1327,  0.3422,  0.3552]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.82, -1.85, -0.32],\n",
       "        [ 0.13,  0.34,  0.36]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.DoubleTensor\n",
      "torch.Size([3, 4, 5])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.randn(3,4,5)\n",
    "print(tensor.type())  # 数据类型\n",
    "print(tensor.size())  # 张量的shape，是个元组\n",
    "print(tensor.dim())   # 维度的数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.11111000, 0.22222200, 0.33333330]], device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[0.11111, 0.222222, 0.3333333]],\n",
    "                 dtype=torch.float64,\n",
    "                 device=torch.device('cuda:0')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensor.data()和tensor.detach()的区别\n",
    "\n",
    "建议使用 `.detach()`, 区别在于 `.data` 返回和 `x` 的相同数据 `tensor`, 但不会加入到`x`的计算历史里，且`requires_grad = False`, 这样有些时候是不安全的, 因为**x.data不能被 autograd追踪求微分**。 `.detach()` 返回相同数据的 `tensor` ,且 `requires_grad=False` ,但能通过 `in-place` 操作报告给 `autograd` 在进行反向传播的时候.  \n",
    "\n",
    "### tensor.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1,2,3.], requires_grad =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7311, 0.8808, 0.9526], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = a.sigmoid()\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7311, 0.8808, 0.9526])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = out.data\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad                #  这个结果很严重的错误，因为out已经改变了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensor.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7311, 0.8808, 0.9526], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3.], requires_grad =True)\n",
    "out = a.sigmoid()\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7311, 0.8808, 0.9526])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = out.detach()\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [3]], which is output 0 of SigmoidBackward, is at version 2; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-4afa0dc2bbec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#  需要原来out得值，但是已经被c.zero_()覆盖了，结果报错\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [3]], which is output 0 of SigmoidBackward, is at version 2; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True)."
     ]
    }
   ],
   "source": [
    "out.sum().backward()  #  需要原来out得值，但是已经被c.zero_()覆盖了，结果报错 ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.as_tensor/zeros/empty/arange/linspace/eye/full/\n",
    "`torch.as_tensor(data, dtype=None, device=None) → Tensor,data:array`  \n",
    "\n",
    "数列转tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.array([1, 2, 3])\n",
    "t = torch.as_tensor(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "t[0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1,  2,  3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(2,3) #shape is (2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [0, 0, 0]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.empty(2, 3, dtype=torch.int64)\n",
    "torch.zeros_like(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.00000000, 1.50000000, 2.00000000])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(1, 2.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-10.,  -5.,   0.,   5.,  10.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(start=-10, end=10, steps=5) #steps:number of points to sample between start and end. Default: 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.14159200, 3.14159200, 3.14159200],\n",
       "        [3.14159200, 3.14159200, 3.14159200]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.full((2, 3), 3.141592)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.cat and torch.chunk\n",
    "`torch.chunk(tensor, chunk_num, dim)`是将`tensor`按`dim`（行或列）分割成`chunk_num`个`tensor`块，返回的是一个元组。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 4.],\n",
      "        [4., 5., 7.],\n",
      "        [3., 9., 8.],\n",
      "        [9., 6., 7.]])\n",
      "torch.Size([4, 3])\n",
      "********************\n",
      "(tensor([[1., 2., 4.]]), tensor([[4., 5., 7.]]), tensor([[3., 9., 8.]]), tensor([[9., 6., 7.]]))\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor([[1,2,4]])\n",
    "b = torch.Tensor([[4,5,7], [3,9,8], [9,6,7]])\n",
    "c = torch.cat((a,b), dim=0)\n",
    "print(c)\n",
    "print(c.size())\n",
    "print('********************')\n",
    "d = torch.chunk(c,4,dim=0)\n",
    "print(d)\n",
    "print(len(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.narrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parameter:\n",
    "\n",
    "`input (Tensor) – the tensor to narrow`    \n",
    "`dim (int) – the dimension along which to narrow`    \n",
    "`start (int) – the starting dimension`  \n",
    "`length (int) – the distance to the ending dimension`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.narrow(x, 0, 0, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3],\n",
       "        [5, 6],\n",
       "        [8, 9]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.narrow(x, 1, 1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.nonzero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/conda-bld/pytorch_1587428398394/work/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0],\n",
       "        [1, 1],\n",
       "        [2, 2],\n",
       "        [3, 3]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nonzero(torch.tensor([[0.6, 0.0, 0.0, 0.0],\n",
    "                            [0.0, 0.4, 0.0, 0.0],\n",
    "                            [0.0, 0.0, 1.2, 0.0],\n",
    "                            [0.0, 0.0, 0.0,-0.4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3]), tensor([0, 1, 2, 3]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nonzero(torch.tensor([[0.6, 0.0, 0.0, 0.0],\n",
    "                                [0.0, 0.4, 0.0, 0.0],\n",
    "                                [0.0, 0.0, 1.2, 0.0],\n",
    "                                [0.0, 0.0, 0.0,-0.4]]), as_tuple=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.unsqueeze  \n",
    "扩展维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "tensor([1., 2., 3., 4.])\n",
      "torch.Size([4])\n",
      "1\n",
      "[1. 2. 3. 4.]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.Tensor([1, 2, 3, 4])  # torch.Tensor是默认的tensor类型（torch.FlaotTensor）的简称。\n",
    "\n",
    "print('-' * 50)\n",
    "print(x)  # tensor([1., 2., 3., 4.])\n",
    "print(x.size())  # torch.Size([4])\n",
    "print(x.dim())  # 1\n",
    "print(x.numpy())  # [1. 2. 3. 4.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "tensor([[1., 2., 3., 4.]])\n",
      "torch.Size([1, 4])\n",
      "2\n",
      "[[1. 2. 3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "print('-' * 50)\n",
    "print(torch.unsqueeze(x, 0))  # tensor([[1., 2., 3., 4.]])\n",
    "print(torch.unsqueeze(x, 0).size())  # torch.Size([1, 4])\n",
    "print(torch.unsqueeze(x, 0).dim())  # 2\n",
    "print(torch.unsqueeze(x, 0).numpy())  # [[1. 2. 3. 4.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.]])\n",
      "torch.Size([4, 1])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print('-' * 50)\n",
    "print(torch.unsqueeze(x, 1))\n",
    "print(torch.unsqueeze(x, 1).size())  # torch.Size([4, 1])\n",
    "print(torch.unsqueeze(x, 1).dim())  # 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.]])\n",
      "torch.Size([4, 1])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print('-' * 50)\n",
    "print(torch.unsqueeze(x, -1))\n",
    "print(torch.unsqueeze(x, -1).size())  # torch.Size([4, 1])\n",
    "print(torch.unsqueeze(x, -1).dim())  # 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "tensor([[1., 2., 3., 4.]])\n",
      "torch.Size([1, 4])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print('-' * 50)\n",
    "print(torch.unsqueeze(x, -2))  # tensor([[1., 2., 3., 4.]])\n",
    "print(torch.unsqueeze(x, -2).size())  # torch.Size([1, 4])\n",
    "print(torch.unsqueeze(x, -2).dim())  # 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`unsqueeze_` 和`unsqueeze` 实现一样的功能,区别在于 `unsqueeze_` 是 `in_place` 操作,即 `unsqueeze` 不会对使用 `unsqueeze` 的 `tensor` 进行改变,想要获取 `unsqueeze` 后的值必须赋予个新值, `unsqueeze_` 则会对自己改变。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.squeeze  \n",
    "将输入张量形状中的1 去除并返回。 如果输入是形如(A×1×B×1×C×1×D)，那么输出形状就为： (A×B×C×D)\n",
    "当给定dim时，那么挤压操作只在给定维度上。例如，输入形状为: (A×1×B), squeeze(input, 0) 将会保持张量不变，只有用 squeeze(input, 1)，形状会变成 (A×B)。\n",
    "\n",
    "多维张量本质上就是一个变换，如果维度是 1 ，那么，1 仅仅起到扩充维度的作用，而没有其他用途，因而，在进行降维操作时，为了加快计算，是可以去掉这些 1 的维度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 2, 1, 2])\n",
      "torch.Size([2, 2, 2])\n",
      "torch.Size([2, 1, 2, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "m = torch.zeros(2, 1, 2, 1, 2)\n",
    "print(m.size())  # torch.Size([2, 1, 2, 1, 2])\n",
    "\n",
    "n = torch.squeeze(m)\n",
    "print(n.size())  # torch.Size([2, 2, 2])\n",
    "\n",
    "n = torch.squeeze(m, 0)  # 当给定dim时，那么挤压操作只在给定维度上\n",
    "print(n.size())  # torch.Size([2, 1, 2, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = torch.squeeze(m, 1)\n",
    "print(n.size())  # torch.Size([2, 2, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 2, 1, 2])\n",
      "torch.Size([2, 1, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "n = torch.squeeze(m, 2)\n",
    "print(n.size())  # torch.Size([2, 1, 2, 1, 2])\n",
    "\n",
    "n = torch.squeeze(m, 3)\n",
    "print(n.size())  # torch.Size([2, 1, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor[N, C, H, W]\n",
    "images = torch.randn(32, 3, 56, 56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 56, 56])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.sum(dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/conda-bld/pytorch_1587428398394/work/c10/core/TensorImpl.h:806: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable.\n"
     ]
    }
   ],
   "source": [
    "NCHW = ['N', 'C', 'H', 'W']\n",
    "images = torch.randn(32, 3, 56, 56, names=NCHW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 56, 56])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.sum('C').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 5.6744e-01,  4.1752e-01,  2.8830e-01,  ..., -8.4218e-01,\n",
       "          -2.1659e-01, -9.8932e-01],\n",
       "         [ 1.1841e+00, -1.5200e+00, -1.2679e-02,  ..., -1.4709e+00,\n",
       "           2.9981e-01, -1.3500e+00],\n",
       "         [ 7.9807e-01,  1.0632e+00, -1.2566e+00,  ...,  6.1915e-01,\n",
       "          -1.3127e+00,  1.3306e-01],\n",
       "         ...,\n",
       "         [ 2.1473e+00, -8.3112e-01,  1.4068e+00,  ..., -7.4190e-01,\n",
       "           2.0996e+00, -1.2519e+00],\n",
       "         [-3.0205e-01,  3.9233e-03, -4.0610e-01,  ...,  4.1151e-01,\n",
       "           3.7060e-01,  1.5014e-01],\n",
       "         [ 1.3275e-01, -1.1107e+00,  1.2884e+00,  ...,  1.1835e-01,\n",
       "           1.3068e+00,  1.6116e-01]],\n",
       "\n",
       "        [[ 3.6937e-01,  2.1532e-01, -1.0256e+00,  ..., -2.1193e-01,\n",
       "           9.5672e-02,  1.5446e+00],\n",
       "         [ 5.0710e-01, -4.4327e-01,  4.4714e-01,  ..., -1.2731e+00,\n",
       "          -4.8913e-01,  8.1772e-01],\n",
       "         [-3.6150e-01,  7.9346e-01,  4.3908e-01,  ..., -1.7832e-01,\n",
       "          -3.3333e-01, -1.1776e+00],\n",
       "         ...,\n",
       "         [-8.9571e-01,  2.1155e+00,  1.9084e-02,  ...,  1.0032e+00,\n",
       "           6.7256e-01,  4.6426e-01],\n",
       "         [-1.1277e+00, -7.5367e-02, -3.6754e-02,  ..., -5.2815e-01,\n",
       "          -4.3337e-01, -1.4523e+00],\n",
       "         [ 6.0726e-02,  1.9997e+00, -3.7401e-01,  ...,  3.4325e-01,\n",
       "           5.4312e-01, -4.8730e-01]],\n",
       "\n",
       "        [[-1.0952e+00, -1.3036e+00,  3.3063e-01,  ..., -7.5227e-01,\n",
       "           7.6247e-01, -7.6985e-01],\n",
       "         [ 3.7081e-01, -3.4101e-01, -1.8533e+00,  ...,  1.7107e+00,\n",
       "           1.3564e+00, -2.9467e-01],\n",
       "         [-1.2604e+00, -3.2394e-02, -4.2860e-01,  ..., -7.6369e-01,\n",
       "          -2.1376e-02,  1.3429e+00],\n",
       "         ...,\n",
       "         [ 8.5770e-01,  1.7567e+00, -3.5681e-01,  ..., -1.2674e+00,\n",
       "           2.4379e-01, -2.7547e+00],\n",
       "         [ 3.9804e-01,  1.7703e-01,  4.3672e-01,  ...,  2.0730e+00,\n",
       "           6.1028e-01,  5.8297e-01],\n",
       "         [ 1.5312e+00, -5.9547e-01,  4.1028e-01,  ...,  4.8005e-01,\n",
       "           8.0279e-02,  8.7265e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 5.1553e-01, -1.7048e-02, -7.2547e-01,  ...,  1.5348e+00,\n",
       "           6.4391e-01, -1.8127e+00],\n",
       "         [-9.9997e-01,  6.5209e-01,  9.8783e-01,  ..., -4.5011e-01,\n",
       "           2.7668e-01,  2.4709e-01],\n",
       "         [-2.0606e+00, -5.9862e-02, -1.0984e+00,  ..., -1.1288e+00,\n",
       "           1.0580e+00,  2.6202e-02],\n",
       "         ...,\n",
       "         [-2.3742e-01,  2.2446e+00, -1.1487e-01,  ...,  1.4910e+00,\n",
       "          -2.1741e-02, -8.1595e-01],\n",
       "         [-1.0254e-02, -1.9362e+00, -1.1620e+00,  ..., -2.3521e-01,\n",
       "          -3.7648e-01, -1.0864e-01],\n",
       "         [ 6.1649e-01, -2.2608e-01, -3.2431e-01,  ...,  7.1727e-01,\n",
       "          -4.6916e-01,  1.6390e+00]],\n",
       "\n",
       "        [[ 8.1943e-01, -2.0197e+00,  2.2432e+00,  ..., -1.8487e-01,\n",
       "           7.7922e-01,  6.6248e-02],\n",
       "         [-9.7136e-01, -4.5828e-01,  8.2244e-01,  ...,  3.9421e+00,\n",
       "          -5.9814e-01, -3.0224e-01],\n",
       "         [ 7.8449e-01,  6.1549e-01,  3.8540e-01,  ...,  1.3037e+00,\n",
       "           7.3336e-01, -3.5654e-01],\n",
       "         ...,\n",
       "         [-1.4814e-01,  1.0789e+00, -4.4617e-01,  ...,  8.8753e-01,\n",
       "          -5.1112e-01,  1.2105e+00],\n",
       "         [ 1.1811e+00,  2.6669e-01, -3.5080e-01,  ..., -3.3841e-01,\n",
       "          -3.6590e+00, -1.3840e+00],\n",
       "         [-6.1897e-01, -1.9911e-02,  5.2520e-01,  ..., -2.6809e-01,\n",
       "           1.0025e-01,  2.7156e-01]],\n",
       "\n",
       "        [[ 7.6381e-01, -1.1866e+00,  2.1231e-01,  ...,  7.4042e-01,\n",
       "          -1.6110e+00, -2.3756e+00],\n",
       "         [ 3.5746e-03,  3.1918e-01,  8.7622e-01,  ..., -1.9978e-01,\n",
       "          -4.3805e-01, -3.6976e-01],\n",
       "         [-1.0227e-01, -9.0272e-01, -3.2976e-01,  ..., -1.6578e-01,\n",
       "          -1.0427e-01,  3.1180e-01],\n",
       "         ...,\n",
       "         [-1.3295e+00,  6.3419e-01, -6.1738e-01,  ...,  6.5884e-01,\n",
       "           7.8723e-02,  1.4568e+00],\n",
       "         [ 7.7213e-01, -6.1608e-01, -1.0237e+00,  ...,  5.7730e-01,\n",
       "           5.0959e-01, -8.4181e-02],\n",
       "         [-1.4792e-01,  7.6563e-01, -9.1248e-01,  ...,  1.7751e+00,\n",
       "          -1.2048e+00,  5.7987e-01]]], names=('N', 'H', 'W'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.select('C', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.rand(3,4,1,2,names=('C', 'N', 'H', 'W'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 1, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = tensor.align_to('N', 'C', 'H', 'W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 1, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  0,   0, 255,  ...,   0, 255,   0],\n",
       "         [  0, 242,   0,  ...,   0,   0,   0],\n",
       "         [255,   0,   0,  ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0,  ..., 110,   0, 139],\n",
       "         [  0, 147,   0,  ..., 153,  15, 185],\n",
       "         [  0,  11,   0,  ...,   0, 146, 174]],\n",
       "\n",
       "        [[230,   0, 255,  ..., 140,   0, 255],\n",
       "         [  0, 177, 229,  ...,   0, 236,   0],\n",
       "         [  0, 255, 184,  ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,  57,  ..., 255,   0,  62],\n",
       "         [ 86,   0,   0,  ...,   0,   0, 213],\n",
       "         [255, 255,   0,  ...,   0,  78,   0]],\n",
       "\n",
       "        [[  0,   0,   0,  ...,  54,   0, 242],\n",
       "         [  0, 113, 114,  ..., 255, 154, 128],\n",
       "         [114,   0, 255,  ..., 244, 255,   0],\n",
       "         ...,\n",
       "         [ 87,   0,   0,  ...,   0,   0,  76],\n",
       "         [  0,   0,   0,  ...,   0,   0, 255],\n",
       "         [  0, 177,   0,  ...,  72, 255, 136]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.Tensor -> PIL.Image.  \n",
    "torch.clamp(img_2 * 255, min=0, max=255).byte()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = torch.clamp(img_2 * 255, min=0, max=255).byte().permute(1, 2, 0).cpu().numpy() # permute：维度换位　\n",
    "#image = torchvision.transforms.functional.to_pil_image(img_2)  # Equivalently way\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIL.Image -> torch.Tensor.\n",
    "tensor = torch.from_numpy(np.asarray(PIL.Image.open('/home/weiweia92/Downloads/kobe.jpeg'))).permute(2, 0, 1).float()/255\n",
    "#tensor = torchvision.transforms.functional.to_tensor(PIL.Image.open(path))  # Equivalently way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### np.ndarray与PIL.Image转换\n",
    "\n",
    "`# np.ndarray -> PIL.Image.`\n",
    "`image = PIL.Image.fromarray(ndarray.astypde(np.uint8))`\n",
    "\n",
    "`# PIL.Image -> np.ndarray.`\n",
    "`ndarray = np.asarray(PIL.Image.open(path))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = torch.rand(1).item() # 提取值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2026575207710266"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensor 变形  \n",
    "在将卷积层输入全连接层的情况下通常需要对张量做形变处理，\n",
    "相比`torch.view，torch.reshape`可以自动处理输入张量不连续的情况。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.rand(2,3,4)\n",
    "shape = (6, 4)\n",
    "tensor = torch.reshape(tensor, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 4])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.50822594, -0.53035324, -1.06180327],\n",
       "        [-0.53724749,  0.00923640,  0.29436072]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.transpose和torch.permute的区别  \n",
    "相同点:都是交换维度用的  \n",
    "不同点:\n",
    "`Tensor.permute(a,b,c,d, ...)：permute`函数可以对任意高维矩阵进行转置，但没有 `torch.permute()` 这个调用方式， 只能 `Tensor.permute()`  \n",
    "`torch.transpose(Tensor, a,b)：transpose`只能操作2D矩阵的转置，有两种调用方式  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.50822594, -0.53724749],\n",
       "        [-0.53035324,  0.00923640],\n",
       "        [-1.06180327,  0.29436072]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.transpose(x, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 5])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 3, 5)\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2, 3])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.permute(2, 0, 1).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_cpu = torch.Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f45ad2a0550>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_cpu.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_cuda = torch.Generator(device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f45ad2a03d0>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_cuda.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.Generator's method \n",
    "`get_state`  \n",
    "`initial_seed`  \n",
    "`manual_seed`  \n",
    "`seed`  \n",
    "`set_state`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  1, 209, 156,  ...,   0,   0,   0], dtype=torch.uint8)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_cpu.get_state() # a torch.ByteTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67280421310721"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_cpu.initial_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f45ad2a0550>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_cpu.manual_seed(2147483647)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Sampling   \n",
    "`torch.seed()`\n",
    "`torch.manual_seed(seed)`  \n",
    "`torch.initial_seed()`  \n",
    "`torch.get_rng_state()`  \n",
    "`torch.set_rng_state()`  \n",
    "`torch.default_generator`  \n",
    "\n",
    "### 概率统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.29625628, 0.10042466, 0.94973225],\n",
       "        [0.02867882, 0.46407592, 0.45112413],\n",
       "        [0.99227606, 0.27476751, 0.11713139]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.empty(3, 3).uniform_(0, 1)  # generate a uniform random matrix with range [0, 1]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 1., 0.]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.bernoulli(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.44029525, 2.09361571, 1.39344268, 4.79772939, 5.50238010, 6.08322211,\n",
       "        7.40052536, 7.77761422, 8.85335743, 9.91384263])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.normal(mean=torch.arange(1., 11.), std=torch.arange(1, 0, -0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1., 3., 0.],\n",
       "        [4., 0., 2., 0.],\n",
       "        [0., 5., 1., 0.],\n",
       "        [0., 1., 0., 1.]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rates = torch.rand(4, 4) * 5\n",
    "torch.poisson(rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 4],\n",
       "        [3, 9]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(3, 10, (2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.08835184, -0.04653659,  0.82810138],\n",
       "        [-0.10339053,  0.52852463,  0.75752584]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.unbind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.50822594, -0.53035324, -1.06180327]),\n",
       " tensor([-0.53724749,  0.00923640,  0.29436072]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unbind(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.take  \n",
    "将`input tensor`视为一维tensor，按照索引取值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 5, 8])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = torch.tensor([[4, 3, 5],[6, 7, 8]])\n",
    "torch.take(src, torch.tensor([0, 2, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.67208683e-02,  2.12627604e+00],\n",
       "        [-1.70442794e+00, -7.90883500e-02],\n",
       "        [-2.75677552e-04, -3.71878714e-01]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, 2)\n",
    "y = torch.ones(3, 2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.00000000, 2.12627604],\n",
       "        [1.00000000, 1.00000000],\n",
       "        [1.00000000, 1.00000000]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(x>0, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 打乱顺序\n",
    "\n",
    "`tensor = tensor[torch.randperm(tensor.size(0))]  # Shuffle the first dimension`  \n",
    "\n",
    "### 水平翻转\n",
    "\n",
    "`PyTorch`不支持`tensor[::-1]`这样的负步长操作，水平翻转可以用张量索引实现。\n",
    "\n",
    "`# Assume tensor has shape N*D*H*W.`\n",
    "`tensor = tensor[:, :, :, torch.arange(tensor.size(3) - 1, -1, -1).long()]`  \n",
    "\n",
    "### 复制张量\n",
    "\n",
    "有三种复制的方式，对应不同的需求。   \n",
    "|`tensor.clone()`         |    `New/Shared memory      New `        | `Still in computation graph         Yes` |   \n",
    "|`tensor.detach()`        |    `New/Shared memory      Shared`      | `Still in computation graph          No` |  \n",
    "|`tensor.detach.clone()()`|    `New/Shared memory      New`         | `Still in computation graph          No` |  \n",
    "\n",
    "### 拼接张量\n",
    "\n",
    "注意`torch.cat`和`torch.stac`k的区别在于`torch.cat`沿着给定的维度拼接，而`torch.stack`会新增一维。例如当参数是3个10×5的张量，`torch.cat`的结果是30×5的张量，而`torch.stack`的结果是3×10×5的张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor1 = torch.rand(10, 5)\n",
    "tensor2 = torch.rand(10, 5)\n",
    "tensor3 = torch.rand(10, 5)\n",
    "tensor_cat = torch.cat([tensor1, tensor2, tensor3], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 5])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 5])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_cat.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor1 = torch.rand(10, 5)\n",
    "tensor2 = torch.rand(10, 5)\n",
    "tensor3 = torch.rand(10, 5)\n",
    "tensor_stack = torch.stack([tensor1, tensor2, tensor3], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10, 5])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_stack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.rand(3, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0219, 0.6251],\n",
       "         [0.0798, 0.6325]],\n",
       "\n",
       "        [[0.9203, 0.3982],\n",
       "         [0.0589, 0.8266]],\n",
       "\n",
       "        [[0.8809, 0.1143],\n",
       "         [0.9980, 0.5072]]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = tensor.size(0)\n",
    "N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.get_num_threads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.get_num_threads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locally disabling gradient computation  \n",
    "\n",
    "These context managers are thread local, so they won’t work if you send work to another thread using the threading module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 判断两个tensor相等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(tensor1, tensor2)  # float tensor\n",
    "torch.equal(tensor1, tensor2)     # int tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 矩阵乘法\n",
    "\n",
    "`# Matrix multiplication: (m*n) * (n*p) -> (m*p).`  \n",
    "`result = torch.mm(tensor1, tensor2)`  \n",
    "\n",
    "`# Batch matrix multiplication: (b*m*n) * (b*n*p) -> (b*m*p).`  \n",
    "`result = torch.bmm(tensor1, tensor2)`  \n",
    "\n",
    "`# Element-wise multiplication.`  \n",
    "`result = tensor1 * tensor2`  \n",
    "计算两组数据之间的两两欧式距离  \n",
    "\n",
    "`# X1 is of shape m*d, X2 is of shape n*d.`  \n",
    "`dist = torch.sqrt(torch.sum((X1[:,None,:] - X2) ** 2, dim=2))`   \n",
    "\n",
    "## 模型定义  \n",
    "\n",
    "### 卷积层\n",
    "\n",
    "最常用的卷积层配置是\n",
    "\n",
    "`conv = torch.nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True)`  \n",
    "`conv = torch.nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=True)`  \n",
    "\n",
    "### GAP（Global average pooling）层\n",
    "\n",
    "`gap = torch.nn.AdaptiveAvgPool2d(output_size=1)`  \n",
    "\n",
    "### 双线性汇合（bilinear pooling)  \n",
    "`\n",
    "X = torch.reshape(N, D, H * W)                        # Assume X has shape N*D*H*W\n",
    "X = torch.bmm(X, torch.transpose(X, 1, 2)) / (H * W)  # Bilinear pooling\n",
    "assert X.size() == (N, D, D)\n",
    "X = torch.reshape(X, (N, D * D))\n",
    "X = torch.sign(X) * torch.sqrt(torch.abs(X) + 1e-5)   # Signed-sqrt normalization\n",
    "X = torch.nn.functional.normalize(X)                  # L2 normalization`  \n",
    "\n",
    "### 多卡同步BN（Batch normalization）\n",
    "\n",
    "当使用`torch.nn.DataParallel`将代码运行在多张GPU卡上时，PyTorch的BN层默认操作是各卡上数据独立地计算均值和标准差，同步BN使用所有卡上的数据一起计算BN层的均值和标准差，缓解了当批量大小`（batch size）`比较小时对均值和标准差估计不准的情况，是在目标检测等任务中一个有效的提升性能的技巧。\n",
    "\n",
    "现在PyTorch官方已经支持同步BN操作\n",
    "\n",
    "`sync_bn = torch.nn.SyncBatchNorm(num_features, eps=1e-05, momentum=0.1, affine=True, \n",
    "                                 track_running_stats=True)`  \n",
    "\n",
    "将已有网络的所有BN层改为同步BN层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't assign to function call (<ipython-input-76-801794ad3fe5>, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-76-801794ad3fe5>\"\u001b[0;36m, line \u001b[0;32m18\u001b[0m\n\u001b[0;31m    setattr(module, name) = convert_syncbn_model(child_module, process_group=process_group)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't assign to function call\n"
     ]
    }
   ],
   "source": [
    "def convertBNtoSyncBN(module, process_group=None):\n",
    "    '''Recursively replace all BN layers to SyncBN layer.\n",
    "\n",
    "    Args:\n",
    "        module[torch.nn.Module]. Network\n",
    "    '''\n",
    "    if isinstance(module, torch.nn.modules.batchnorm._BatchNorm):\n",
    "        sync_bn = torch.nn.SyncBatchNorm(module.num_features, module.eps, module.momentum, \n",
    "                                         module.affine, module.track_running_stats, process_group)\n",
    "        sync_bn.running_mean = module.running_mean\n",
    "        sync_bn.running_var = module.running_var\n",
    "        if module.affine:\n",
    "            sync_bn.weight = module.weight.clone().detach()\n",
    "            sync_bn.bias = module.bias.clone().detach()\n",
    "        return sync_bn\n",
    "    else:\n",
    "        for name, child_module in module.named_children():\n",
    "            setattr(module, name) = convert_syncbn_model(child_module, process_group=process_group)\n",
    "        return module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算模型整体参数量\n",
    "\n",
    "\n",
    "`# torch.numel:返回输入张量中元素的总数   \n",
    "num_parameters = sum(torch.numel(parameter) for parameter in model.parameters())`  \n",
    "\n",
    "### 模型权值初始化\n",
    "\n",
    "注意`model.modules()`和`model.children()`的区别：`model.modules()`会迭代地遍历模型的所有子层，而`model.children()`只会返回模型最外层的子层\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`# Common practise for initialization.\n",
    "for layer in model.modules():\n",
    "    if isinstance(layer, torch.nn.Conv2d):\n",
    "        torch.nn.init.kaiming_normal_(layer.weight, mode='fan_out',\n",
    "                                      nonlinearity='relu')\n",
    "        if layer.bias is not None:\n",
    "            torch.nn.init.constant_(layer.bias, val=0.0)\n",
    "    elif isinstance(layer, torch.nn.BatchNorm2d):\n",
    "        torch.nn.init.constant_(layer.weight, val=1.0)\n",
    "        torch.nn.init.constant_(layer.bias, val=0.0)\n",
    "    elif isinstance(layer, torch.nn.Linear):\n",
    "        torch.nn.init.xavier_normal_(layer.weight)\n",
    "        if layer.bias is not None:\n",
    "            torch.nn.init.constant_(layer.bias, val=0.0)`\n",
    "\n",
    "`# Initialization with given tensor.\n",
    "layer.weight = torch.nn.Parameter(tensor)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch其他注意事项\n",
    "\n",
    "### 模型定义\n",
    "\n",
    "建议有参数的层和汇合`（pooling）`层使用`torch.nn`模块定义，激活函数直接使用`torch.nn.functional`。`torch.nn`模块和`torch.nn.functional`的区别在于，`torch.nn`模块在计算时底层调用了`torch.nn.functional`，但`torch.nn`模块包括该层参数，还可以应对训练和测试两种网络状态。使用`torch.nn.functional`时要注意网络状态，如\n",
    "`def forward(self, x):\n",
    "    ...\n",
    "    x = torch.nn.functional.dropout(x, p=0.5, training=self.training)`\n",
    "`model(x)`前用`model.train()`和`model.eval()`切换网络状态。\n",
    "不需要计算梯度的代码块用`with torch.no_grad()`包含起来。`model.eval()`和`torch.no_grad()`的区别在于，`model.eval()`是将网络切换为测试状态，例如BN和dropout在训练和测试阶段使用不同的计算方法。`torch.no_grad()`是关闭`PyTorch`张量的自动求导机制，以减少存储使用和加速计算，得到的结果无法进行`loss.backward()`。\n",
    "`torch.nn.CrossEntropyLoss`的输入不需要经过`Softmax`。`torch.nn.CrossEntropyLoss`等价于`torch.nn.functional.log_softmax + torch.nn.NLLLoss`。\n",
    "`loss.backward()`前用`optimizer.zero_grad()`清除累积梯度。`optimizer.zero_grad()`和`model.zero_grad()`效果一样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
