{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4f51bfa-7d66-49f1-a2d4-b5928bd4c834",
   "metadata": {},
   "source": [
    "# Lesson 2 张量的索引，分片，合并以及维度调整\n",
    "\n",
    "张量作为有序的序列，也是具备数据索引的功能，并且基本索引方法和Python原生的列表，NumPy中的数组基本一致，当然所不同的是PyTorch还定义了一种采用函数来进行索引的方式。\n",
    "\n",
    "而作为PyTorch中基本数据类型，张量即具备了列表，数组的基本功能，同时还充当了向量，矩阵甚至数据框等重要数据结构，因此PyTorch中设置了非常完备的张量合并与变换的操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f9fe81f-5103-4b43-9593-0bb4beb3e140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cde7ce1-5aa1-45d9-bd97-6513969a7e2c",
   "metadata": {},
   "source": [
    "## 一.张量的符号索引\n",
    "\n",
    "张量也是**有序序列**，我们可以根据每个元素在系统内的顺序编号，来找出特定的元素，也就是索引。\n",
    "\n",
    "### 1.一维张量索引\n",
    "\n",
    "一维张量的索引过程和Python原生对象类型的索引一致，基本格式遵循`[start:end:step]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a418ef6-55ae-4856-8b12-9b52af85f084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = torch.arange(1, 11)\n",
    "t1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2170bea3-b74a-4f05-93fc-8901897224bd",
   "metadata": {},
   "source": [
    "* 从左到右，从零开始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "876a2cc6-d4dd-4eab-95d1-a49b5cfc3f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4d0ea20-19df-4ceb-9db8-053629ad2474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1[0].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e369a7b0-cfb1-4ad4-a623-2008d1eaa60d",
   "metadata": {},
   "source": [
    "**注：张量的索引出来的结果还是零维张量，而不是单独的数，要转化成单独的数需要使用`item()`方法**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accffc55-94f7-43ab-92f9-e2ab67b9d7ed",
   "metadata": {},
   "source": [
    "* 冒号分割，表示对某个区域进行索引——切片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f068451-b10b-448e-9936-a74780eb8e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3, 4, 5, 6, 7, 8])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1[1:8]  #左闭右开区间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "928d071e-f954-4d1c-a5bd-5894ad13c954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 4, 6, 8])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1[1:8:2]   #第二个冒号表示索引的间隔"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e06a8b-2442-4600-bde3-f57ec4f7d120",
   "metadata": {},
   "source": [
    "* 冒号前后没有值，表示索引这个区域"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6eb089a3-7832-451d-a4b5-e56a6e7f4a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2,  4,  6,  8, 10])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1[1::2]  #从第二个元素开始索引，一直到结尾，并且每隔两个数取一个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e607ac00-ef0e-4ea4-bbc4-c7949f090da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3, 5, 7])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1[:8:2]  #从第一个元素开始索引到第九个元素（不包含），并且每隔2个数取一个"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8526d688-0f7f-4768-8ea9-86f0e0cfffdb",
   "metadata": {},
   "source": [
    "**张量索引中，step位必须大于0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aacfd2eb-ddc7-4d54-91e9-15f04aff0062",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "step must be greater than zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-35b1e79b8702>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: step must be greater than zero"
     ]
    }
   ],
   "source": [
    "t1[9:1:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982db7c4-dfce-4ff0-80cc-d7d53f016141",
   "metadata": {},
   "source": [
    "### 2.二维张量索引\n",
    "\n",
    "二维张量的索引逻辑和一维张量的索引逻辑基本相同，二维张量可以视为两个一维张量组合而成，而在实际的索引过程中，需要用逗号进行分隔，分别表示对哪个一维张量进行索引，以及具体的一维张量的索引。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b530e98f-3c01-411b-9e59-248c7b682fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = torch.arange(1, 10).reshape(3,3)\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55674530-d913-4504-bc5d-e1831d2848e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b993373f-7d04-4b27-8b25-7d4e7b9ac7bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2[0, ::2]   #表示索引第一行，对于列，每隔两个元素取一个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28ae0906-4345-4f00-b272-cc6981b8f34f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2[0, [0, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2def17a-81a5-48a0-8c77-138515b68dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 3],\n",
       "        [7, 9]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2[::2, ::2]  #对于行和列均为每隔两个元素取一个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84051f79-a939-40b0-a9e9-070f69213439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 8])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2[[0, 2], 1]  #取第一行第三行，第二列元素"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419383de-850e-4648-934b-ee4b40d55dc5",
   "metadata": {},
   "source": [
    "理解：对于二维张量，基本可以视为对矩阵的索引，并且行列的索引遵照相同的索引规范，并且用逗号进行分隔\n",
    "\n",
    "### 3.三维张量的索引\n",
    "\n",
    "在二维张量索引的基础上，三维张量拥有三个索引的维度，我们将三维张量视为矩阵组成的序列。在实际索引过程中拥有三个维度，分别为索引矩阵，索引矩阵的行，索引矩阵的列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ef20456-47c8-418f-87f7-c54428dac870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3],\n",
       "         [ 4,  5,  6],\n",
       "         [ 7,  8,  9]],\n",
       "\n",
       "        [[10, 11, 12],\n",
       "         [13, 14, 15],\n",
       "         [16, 17, 18]],\n",
       "\n",
       "        [[19, 20, 21],\n",
       "         [22, 23, 24],\n",
       "         [25, 26, 27]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3 = torch.arange(1, 28).reshape(3, 3, 3)\n",
    "t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5435ead2-263a-485a-a6b3-21ddc7054a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3[1, 1, 1]  #第二个索引矩阵中第二个行第二列元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cfda3c30-b133-423c-b991-50c3534fe0b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10, 12],\n",
       "        [16, 18]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3[1, ::2, ::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc4a324e-6e89-4439-aab3-a0e4d7772c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  3],\n",
       "         [ 7,  9]],\n",
       "\n",
       "        [[19, 21],\n",
       "         [25, 27]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3[::2,::2,::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff506c9-efcb-45ed-b925-ddf4398c6048",
   "metadata": {},
   "source": [
    "理解：更为本质的角度去理解高维张量的索引，其实就是围绕张量的‘形状’进行索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4df97eff-5b35-46a9-8f81-c8b3c3cb1a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 3])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73e9a484-212a-471e-acf0-be7a4945ad3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3[1, 1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed77e57-cee7-4c3f-b9f1-f5a90116b81b",
   "metadata": {},
   "source": [
    "## 二.张量的函数索引\n",
    "\n",
    "在PyTorch中，我们还可以使用`index_select`函数，通过指定`index`对张量进行索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b61baba9-4d05-45e6-960c-6c897a533312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "489dda8b-3b26-498e-9134-e77f3c36b18a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a4390e3-5033-4e27-8410-728d6d305c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = torch.tensor([1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2555f109-0a7f-4273-801a-b727ab28dcf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "84606392-d5f1-4c2f-9129-7633f272dd1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.index_select(t1, 0, indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd1e478-de1d-4f4f-b8b8-61678a858f8b",
   "metadata": {},
   "source": [
    "在`index_select`函数中，第二个参数实际上代表的是索引的维度，对于t1这个一维向量来说，由于只有一个维度，因此第二个参数取值为0，就代表在第一个维度上进行索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6db697b-60f7-44a6-9fff-da67e0df3e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2],\n",
       "        [ 3,  4,  5],\n",
       "        [ 6,  7,  8],\n",
       "        [ 9, 10, 11]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = torch.arange(12).reshape(4, 3)\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d5eb3b7-2ec5-4b00-ac81-7264847631b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7513dc69-02a4-4b1c-b997-18b625f6fc8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a2298b-8223-48bb-976f-65a3b27396a5",
   "metadata": {},
   "source": [
    "dim参数取值为0，代表在shape的第一个维度上索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b01fe0aa-c4ec-4105-a506-6ee931d23d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 4, 5],\n",
       "        [6, 7, 8]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.index_select(t2, 0, indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65168247-d4de-4a7f-a6a1-6880caa88a50",
   "metadata": {},
   "source": [
    "dim参数取值为1，代表在shape的第二个维度上索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ff2f337-ae03-44e4-8167-5c0a45892dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2],\n",
       "        [ 4,  5],\n",
       "        [ 7,  8],\n",
       "        [10, 11]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.index_select(t2, 1, indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb4f064-4f6c-4dec-b8c6-dc3672e2f6cc",
   "metadata": {},
   "source": [
    "## 三.tensor.view()方法\n",
    "\n",
    "在正式介绍张量的切片方法之前，需要先介绍PyTorch中的`.view()`方法。该方法会返回一个类似视图的结果，该结果和原张量对象共享一块数据存储空间，并且通过`.view()`方法，还可以改变对象结构，生成一个不同结构，但共享一个存储空间的张量。当然，共享一个存储空间，也就代表二者是‘浅拷贝’的关系，修改其中一个，另一个也会同步进行更改。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ffa91a32-477a-4217-8840-f51b6610a486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [3, 4, 5]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.arange(6).reshape(2, 3)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "115f3149-5d3e-4431-ab6e-b5663cbc2319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te = t.view(3, 2)   #构建一个数据相同，但形状不同的\"视图\"\n",
    "te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4619151e-5c75-4479-b0e0-2afb34d125c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [3, 4, 5]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a3c2e1cb-b0e8-4f6f-9d18-3e229612d685",
   "metadata": {},
   "outputs": [],
   "source": [
    "t[0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "97ddbd18-8b9b-4107-a373-5d5aa6ad99a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1],\n",
       "        [3, 4, 5]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1d2099eb-62bb-402e-8a32-afbc8a9fe94b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1],\n",
       "        [1, 3],\n",
       "        [4, 5]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te     #同步变化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2374db2a-9572-4a6a-9ec1-7753ef73b96e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 1],\n",
       "         [3, 4, 5]]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr = t.view(1, 2, 3)   #维度也可以修改\n",
    "tr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22b8ca0-cbfc-4dc9-aea7-2a9254cb446d",
   "metadata": {},
   "source": [
    "\"视图\"的作用就是节省空间，值得注意的是，在接下来介绍的很多切分张量的方法中，返回的都是“视图”，而不是新生成一个对象\n",
    "\n",
    "## 四.张量的分片函数\n",
    "\n",
    "### 1.分块：chunk 函数\n",
    "\n",
    "chunk函数能够按照某维度，对张量进行均匀切分，并且返回结果是原张量的视图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "07a9e998-7598-4f96-a10a-8cd11c2e8c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2],\n",
       "        [ 3,  4,  5],\n",
       "        [ 6,  7,  8],\n",
       "        [ 9, 10, 11]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = torch.arange(12).reshape(4, 3)\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7f3987be-a6d3-45dd-afd9-123685afcd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc = torch.chunk(t2, 4, dim=0)   #在第零维上(按行)进行四等分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6fa15580-8c4e-4866-9c20-0b4425e18110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1, 2]]),\n",
       " tensor([[3, 4, 5]]),\n",
       " tensor([[6, 7, 8]]),\n",
       " tensor([[ 9, 10, 11]]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc    #元组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9968edad-b90c-4324-8714-b5680447897c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a33901aa-b2c1-4e39-8d19-a94c7b6910b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc[0][0][0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "656b1b93-1169-4bf2-ad39-cdcb2604ec1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 1, 2]]),\n",
       " tensor([[3, 4, 5]]),\n",
       " tensor([[6, 7, 8]]),\n",
       " tensor([[ 9, 10, 11]]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fe2c1bc6-6dcf-445d-8e0d-ba9e16a7aeb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  1,  2],\n",
       "        [ 3,  4,  5],\n",
       "        [ 6,  7,  8],\n",
       "        [ 9, 10, 11]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2b7f6c-5ab0-4376-995d-74196f25606f",
   "metadata": {},
   "source": [
    "当原张量不能均分时，chunk不会报错，但会返回其他均分的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "29bde0e7-404d-4d87-a35e-dc87dad55e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 1, 2],\n",
       "         [3, 4, 5]]),\n",
       " tensor([[ 6,  7,  8],\n",
       "         [ 9, 10, 11]]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.chunk(t2, 3, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cacd72ed-04de-4b74-9b6a-8fca7b924e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(torch.chunk(t2, 3, dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d309651b-4675-4e60-a580-2a9858fa6fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 1, 2]]),\n",
       " tensor([[3, 4, 5]]),\n",
       " tensor([[6, 7, 8]]),\n",
       " tensor([[ 9, 10, 11]]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.chunk(t2, 5, dim=0)  #返回次一级的均分结果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ea7bce-3d15-4b53-841f-049579ef536a",
   "metadata": {},
   "source": [
    "### 2.拆分：split函数\n",
    "\n",
    "split既能进行均分，也能进行自定义切分。当然，要注意的是，和chunk函数一样，split返回结果也是view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5f3fcd66-1837-43be-8626-f41df0b8a178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2],\n",
       "        [ 3,  4,  5],\n",
       "        [ 6,  7,  8],\n",
       "        [ 9, 10, 11]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = torch.arange(12).reshape(4, 3)\n",
    "t2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1620995f-0c70-4254-b38f-a9b14c9f16da",
   "metadata": {},
   "source": [
    "均分情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2f3b4a26-de8d-4442-b283-859e3f3be086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1, 2],\n",
       "         [3, 4, 5]]),\n",
       " tensor([[ 6,  7,  8],\n",
       "         [ 9, 10, 11]]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.split(t2, 2, 0)  #第二个参数只输入一个数值时表示均分，第三个参数表示进行的维度（0:按行）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cebcd180-f6cb-4fa0-8b58-43542af21015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1, 2]]),\n",
       " tensor([[ 3,  4,  5],\n",
       "         [ 6,  7,  8],\n",
       "         [ 9, 10, 11]]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.split(t2, [1, 3], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33802d8d-b642-4e18-a81f-c1f486960dd7",
   "metadata": {},
   "source": [
    "注意：当第二个参数位输入一个序列时，序列的各数值的和必须等于对应维度下形状分量的取值。例如，上述代码中，按照第一个维度进行切分，而t2总共有4行，因此序列的求和必须等于4，也就是1+3=4，而序列中每个分量的取值则代表切块大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3ec26e18-ee46-4374-a116-d7b150076ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1, 2]]),\n",
       " tensor([[3, 4, 5]]),\n",
       " tensor([[6, 7, 8]]),\n",
       " tensor([[ 9, 10, 11]]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.split(t2, [1, 1, 1, 1], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7bd658be-d40e-4894-9acb-ddfe13e0c277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1, 2]]),\n",
       " tensor([[3, 4, 5]]),\n",
       " tensor([[ 6,  7,  8],\n",
       "         [ 9, 10, 11]]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.split(t2, [1, 1, 2], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "73f10009-1fd6-4e7f-a384-195f02571206",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = torch.split(t2, [1, 2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "01605222-131d-4501-8437-2cdabd33bc5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0],\n",
       "         [3],\n",
       "         [6],\n",
       "         [9]]),\n",
       " tensor([[ 1,  2],\n",
       "         [ 4,  5],\n",
       "         [ 7,  8],\n",
       "         [10, 11]]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7568f585-04cb-47db-b38e-cf4edc5f7602",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts[0][0] = 1 #view进行修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e7d607ae-555a-4d8e-b43b-e02a5ef48b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  1,  2],\n",
       "        [ 3,  4,  5],\n",
       "        [ 6,  7,  8],\n",
       "        [ 9, 10, 11]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2           #原对象同步改变"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40259eb-5015-4ca9-a71f-f94d1c853d28",
   "metadata": {},
   "source": [
    "tensor的split方法和array的split方法有很大的区别，array的split方法时根据索引进行切分。\n",
    "\n",
    "## 五.张量的合并操作\n",
    "\n",
    "张量的合并操作类似于列表的追加元素，可以拼接也可以堆叠\n",
    "\n",
    "* 拼接函数：`cat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "73827ed2-6099-4731-a211-9ae0f2d09238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.zeros(2, 3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8c2dfd0c-b039-43fd-9746-1186d3e5b6dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.ones(2, 3)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ef24c1be-d501-4c81-9f96-55cf8c07aaec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = torch.zeros(3, 3)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a1d7ccd8-43f1-4ed3-a8ad-797ae9698c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([a, b])  #按照行进行拼接，dim默认取值为0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "210e2fcf-df72-4143-84f8-b5920a973cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 1., 1., 1.],\n",
       "        [0., 0., 0., 1., 1., 1.]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([a, b], 1) #按照列进行拼接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "175c66c2-65d8-4218-9c76-ab823b643b76",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Got 2 and 3 in dimension 0 (The offending index is 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-8b4c660972f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#形状不匹配时将报错\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Got 2 and 3 in dimension 0 (The offending index is 1)"
     ]
    }
   ],
   "source": [
    "torch.cat([a, c], 1)  #形状不匹配时将报错"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe807d9a-86d9-498c-9fcf-e8a7d20376d3",
   "metadata": {},
   "source": [
    "**注意：拼接的本质时实现元素的堆积，也就是构成a, b两个二维张量的各一维张量的堆积，最终还是构成二维向量**\n",
    "\n",
    "* 堆叠函数：`stack`\n",
    "\n",
    "和拼接不同，堆叠不是将元素拆分重装，而是简单的将各参与堆叠的对象分装到一个更高维度的张量里。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a7cb4978-0c34-47a3-ba6e-d5d8ae1b4439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b3bea989-40da-451c-9c1f-80f7309de08f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "742c1f05-96e1-4cc7-9db7-144e4f849f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.]]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([a, b])  #堆叠之后生成一个三维张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1b191767-ca88-4fb9-97f7-16308f11b31e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([a, b]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fc39e521-800f-43dc-b1fb-cb14976f6270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([a, b]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7832f405-0ebb-4dac-af13-1826a993a069",
   "metadata": {},
   "source": [
    "注意对比二者区别，拼接之后维度不变，堆叠之后维度升高。拼接是把一个个元素单独提取出来之后再放到二维张量中，而堆叠则是直接将两个二维张量封装到一个三维张量中，因此堆叠的要求更高，参与堆叠的张量必须形状完全相同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b847d1c9-4598-4cdb-a64e-ce1a39862e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "22b480d5-9bde-4168-8068-1abe8bfdb34a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4f18c73b-ff89-4c38-a9d5-ae9c7cff9aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([a, c])   #横向拼接时，对行数没有一致性要求"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9f0be236-5d14-4555-a7a1-22583235e162",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [2, 3] at entry 0 and [3, 3] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-849f563bf74a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [2, 3] at entry 0 and [3, 3] at entry 1"
     ]
    }
   ],
   "source": [
    "torch.stack([a, c])  #维数不匹配报错"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311d0f5d-87f1-46b9-b0c7-1e7b7b1c7fb1",
   "metadata": {},
   "source": [
    "## 六.张量维度变换\n",
    "\n",
    "通过reshape方法能够灵活调整张量的形状，而在实际操作张量进行计算时，往往需要另外进行降维和升维操作，当我们需要除去不必要的维度时，可以使用`squeeze`函数。而需要手动升维时，则可采用`unsqueeze`函数。\n",
    "\n",
    "* `squeeze`函数：删除不必要的维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fd0e9d16-f85f-41c0-ba49-4b957a2d7b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(4)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d63abee9-437f-4e85-b588-f8ab5e2bced5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2 = a.reshape(1, 4)\n",
    "a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9e9dd6ba-2bb4-4cfb-b1c0-38b0875ccc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.zeros(1, 1, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dff40a61-d45c-4e3b-b811-92c08d50142f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.],\n",
       "          [0.],\n",
       "          [0.]]]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t  #一个包含一个三维的四维张量,三维张量包含一个二维矩阵张量（三行一列）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7b923d81-4517-4443-a820-54e789411f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 3, 1])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d1203285-fbe0-4a96-b806-6c029943bda2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.squeeze(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "89495764-ae5a-4716-a597-4d927419b82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.squeeze(t).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca707ae-ab9c-4da0-a0c2-e5f5e571f602",
   "metadata": {},
   "source": [
    "转化后生成了一个一维张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "340d4755-6f9f-4e1e-b931-ed2e811ace2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 3, 2, 1, 2])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = torch.zeros(1, 1, 3, 2, 1, 2)\n",
    "t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "07c45f9b-19bd-4577-b9d8-a1118de82a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.squeeze(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "92401949-9326-4113-a605-8cf0552aada7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.squeeze(t1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d856e71c-60f9-49ad-a8f7-ca1424829cb7",
   "metadata": {},
   "source": [
    "简单理解，`squeeze`就相当于剔除了shape返回结果中的1\n",
    "\n",
    "* `unsqeeze`函数：手动升维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7f5195db-a1ca-4a03-b10b-2412fe16ddf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 1, 2])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.zeros(1, 2, 1, 2)\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b87336c8-7a9f-4e2d-bd0e-c12760796af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[0., 0.]],\n",
       "\n",
       "          [[0., 0.]]]]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unsqueeze(t, dim=0)   #在第一个维度索引上升高一个维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "aae61cd7-ad89-4dc0-b4c2-390c00321a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 2, 1, 2])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unsqueeze(t, dim=0).shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ee926166-75a2-4a41-8797-ca820703f841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 1, 1, 2])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unsqueeze(t, dim=2).shape  #在第3个维度索引上升高一个维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fca850a4-71f5-4373-b954-dffea518c115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 1, 2, 1])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unsqueeze(t, dim=4).shape   #在第5个维度索引上升高一个维度     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a11cd6-e8c6-4165-9879-f35c16f24f36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
