{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6784a6-59f9-440a-9b05-d3f1c288fe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.filters\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "\n",
    "def load_wav(path, sr):\n",
    "    return librosa.core.load(path, sr=sr)[0]\n",
    "\n",
    "def save_wav(wav, path, sr):\n",
    "    wav *= 32767 / max(0.01, np.max(np.abs(wav)))\n",
    "    #proposed by @dsmiller\n",
    "    wavfile.write(path, sr, wav.astype(np.int16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c41f61-7135-4379-a5cd-db1812577685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_wavenet_wav(wav, path, sr, inv_preemphasize, k):\n",
    "    wav *= 32767 / max(0.01, np.max(np.abs(wav)))\n",
    "    wavfile.write(path, sr, wav.astype(np.int16))       ????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de24a3bc-b4ee-4a58-9567-bdfb651d7e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preemphasis(wav, k, preemphasize=True):\n",
    "    if preemphasize:\n",
    "        return signal.lfilter([1, -k], [1], wav) # 低通滤波器\n",
    "    return wav\n",
    "\n",
    "def inv_preemphasis(wav, k, inv_preemphasize=True):\n",
    "    if inv_preemphasize:\n",
    "        return signal.lfilter([1], [1, -k], wav)\n",
    "    return wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff9a061-a5ba-4c00-8469-4223b2ad4eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From https://github.com/r9y9/wavenet_vocoder/blob/master/audio.py\n",
    "def start_and_end_indices(quantized, silence_threshold=2):\n",
    "\tfor start in range(quantized.size):\n",
    "\t\tif abs(quantized[start] - 127) > silence_threshold:\n",
    "\t\t\tbreak\n",
    "\tfor end in range(quantized.size - 1, 1, -1):\n",
    "\t\tif abs(quantized[end] - 127) > silence_threshold:\n",
    "\t\t\tbreak\n",
    "\n",
    "\tassert abs(quantized[start] - 127) > silence_threshold\n",
    "\tassert abs(quantized[end] - 127) > silence_threshold\n",
    "\n",
    "\treturn start, end   ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23deef44-1378-4520-8415-cba4fc08b7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_silence(wav, hparams):\n",
    "    '''Trim leading and trailing silence\n",
    "    Useful for M-AILABS dataset if we choose to trim the extra 0.5 silence at beginning and end.\n",
    "    '''\n",
    "    #Thanks @begeekmyfriend and @lautjy for pointing out the params contradiction(矛盾). 这些参数是独立的，每个数据集都可以调整.\n",
    "    return librosa.effects.trim(wav, top_db= hparams.trim_top_db, frame_length=hparams.trim_fft_size, hop_length=hparams.trim_hop_size)[0]   ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737da66c-4eff-4510-97a2-16cec7cfc06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hop_size(hparams):\n",
    "    hop_size = hparams.hop_size\n",
    "    if hop_size is None:\n",
    "        assert hparams.frame_shift_ms is not None\n",
    "        hop_size = int(hparams.frame_shift_ms / 1000 * hparams.sample_rate)\n",
    "    return hop_size\n",
    "\n",
    "def linearspectrogram(wav, hparams):\n",
    "    # D = _stft(preemphasis(wav, hparams.preemphasis, hparams.preemphasize), hparams)\n",
    "    D = _stft(wav, hparams)\n",
    "    S = _amp_to_db(np.abs(D)**hparams.magnitude_power, hparams) - hparams.ref_level_db\n",
    "\n",
    "    if hparams.signal_normalization:\n",
    "        return _normalize(S, hparams)\n",
    "    return S\n",
    "\n",
    "def melspectrogram(wav, hparams):\n",
    "    # D = _stft(preemphasis(wav, hparams.preemphasis, hparams.preemphasize), hparams)\n",
    "    D = _stft(wav, hparams)\n",
    "    S = _amp_to_db(_linear_to_mel(np.abs(D)**hparams.magnitude_power, hparams), hparams) - hparams.ref_level_db\n",
    "\n",
    "    if hparams.signal_normalization:\n",
    "        return _normalize(S, hparams)\n",
    "    return S\n",
    "\n",
    "def inv_linear_spectrogram(linear_spectrogram, hparams):\n",
    "    '''Converts linear spectrogram to waveform using librosa'''\n",
    "    if hparams.signal_normalization:\n",
    "        D = _denormalize(linear_spectrogram, hparams)\n",
    "    else:\n",
    "        D = linear_spectrogram\n",
    "\n",
    "    S = _db_to_amp(D + hparams.ref_level_db)**(1/hparams.magnitude_power) #Convert back to linear\n",
    "\n",
    "    if hparams.use_lws:\n",
    "        processor = _lws_processor(hparams)\n",
    "        D = processor.run_lws(S.astype(np.float64).T ** hparams.power)\n",
    "        y = processor.istft(D).astype(np.float32)\n",
    "        return inv_preemphasis(y, hparams.preemphasis, hparams.preemphasize)\n",
    "    else:\n",
    "        return inv_preemphasis(_griffin_lim(S ** hparams.power, hparams), hparams.preemphasis, hparams.preemphasize)\n",
    "\n",
    "\n",
    "def inv_mel_spectrogram(mel_spectrogram, hparams):\n",
    "    '''Converts mel spectrogram to waveform using librosa'''\n",
    "    if hparams.signal_normalization:\n",
    "        D = _denormalize(mel_spectrogram, hparams)\n",
    "    else:\n",
    "        D = mel_spectrogram\n",
    "\n",
    "    S = _mel_to_linear(_db_to_amp(D + hparams.ref_level_db)**(1/hparams.magnitude_power), hparams)  # Convert back to linear\n",
    "\n",
    "    if hparams.use_lws:\n",
    "        processor = _lws_processor(hparams)\n",
    "        D = processor.run_lws(S.astype(np.float64).T ** hparams.power)\n",
    "        y = processor.istft(D).astype(np.float32)\n",
    "        return inv_preemphasis(y, hparams.preemphasis, hparams.preemphasize)\n",
    "    else:\n",
    "        return inv_preemphasis(_griffin_lim(S ** hparams.power, hparams), hparams.preemphasis, hparams.preemphasize)\n",
    "\n",
    "###########################################################################################\n",
    "# tensorflow Griffin-Lim\n",
    "# Thanks to @begeekmyfriend: https://github.com/begeekmyfriend/Tacotron-2/blob/mandarin-new/datasets/audio.py\n",
    "\n",
    "def inv_linear_spectrogram_tensorflow(spectrogram, hparams):\n",
    "    '''Builds computational graph to convert spectrogram to waveform using TensorFlow.\n",
    "    Unlike inv_spectrogram, this does NOT invert the preemphasis. The caller should call\n",
    "    inv_preemphasis on the output after running the graph.\n",
    "    '''\n",
    "    if hparams.signal_normalization:\n",
    "        D = _denormalize_tensorflow(spectrogram, hparams)\n",
    "    else:\n",
    "        D = linear_spectrogram\n",
    "\n",
    "    S = tf.pow(_db_to_amp_tensorflow(D + hparams.ref_level_db), (1/hparams.magnitude_power))\n",
    "    return _griffin_lim_tensorflow(tf.pow(S, hparams.power), hparams)\n",
    "\n",
    "def inv_mel_spectrogram_tensorflow(mel_spectrogram, hparams):\n",
    "    '''Builds computational graph to convert mel spectrogram to waveform using TensorFlow.\n",
    "    Unlike inv_mel_spectrogram, this does NOT invert the preemphasis. The caller should call\n",
    "    inv_preemphasis on the output after running the graph.\n",
    "    '''\n",
    "    if hparams.signal_normalization:\n",
    "        D = _denormalize_tensorflow(mel_spectrogram, hparams)\n",
    "    else:\n",
    "        D = mel_spectrogram\n",
    "\n",
    "    S = tf.pow(_db_to_amp_tensorflow(D + hparams.ref_level_db), (1/hparams.magnitude_power))\n",
    "    S = _mel_to_linear_tensorflow(S, hparams)  # Convert back to linear\n",
    "    return _griffin_lim_tensorflow(tf.pow(S, hparams.power), hparams)\n",
    "\n",
    "###########################################################################################\n",
    "\n",
    "def _lws_processor(hparams):\n",
    "    import lws\n",
    "    return lws.lws(hparams.n_fft, get_hop_size(hparams), fftsize=hparams.win_size, mode=\"speech\")\n",
    "\n",
    "def _griffin_lim(S, hparams):\n",
    "    '''librosa implementation of Griffin-Lim\n",
    "    Based on https://github.com/librosa/librosa/issues/434\n",
    "    '''\n",
    "    angles = np.exp(2j * np.pi * np.random.rand(*S.shape))\n",
    "    S_complex = np.abs(S).astype(np.complex)\n",
    "    y = _istft(S_complex * angles, hparams)\n",
    "    for i in range(hparams.griffin_lim_iters):\n",
    "        angles = np.exp(1j * np.angle(_stft(y, hparams)))\n",
    "        y = _istft(S_complex * angles, hparams)\n",
    "    return y\n",
    "\n",
    "def _griffin_lim_tensorflow(S, hparams):\n",
    "    '''TensorFlow implementation of Griffin-Lim\n",
    "    Based on https://github.com/Kyubyong/tensorflow-exercises/blob/master/Audio_Processing.ipynb\n",
    "    '''\n",
    "    with tf.variable_scope('griffinlim'):\n",
    "        # TensorFlow's stft and istft operate on a batch of spectrograms; create batch of size 1\n",
    "        S = tf.expand_dims(S, 0)\n",
    "        S_complex = tf.identity(tf.cast(S, dtype=tf.complex64))\n",
    "        y = tf.contrib.signal.inverse_stft(S_complex, hparams.win_size, get_hop_size(hparams), hparams.n_fft)\n",
    "        for i in range(hparams.griffin_lim_iters):\n",
    "            est = tf.contrib.signal.stft(y, hparams.win_size, get_hop_size(hparams), hparams.n_fft)\n",
    "            angles = est / tf.cast(tf.maximum(1e-8, tf.abs(est)), tf.complex64)\n",
    "            y = tf.contrib.signal.inverse_stft(S_complex * angles, hparams.win_size, get_hop_size(hparams), hparams.n_fft)\n",
    "    return tf.squeeze(y, 0)\n",
    "\n",
    "def _stft(y, hparams):\n",
    "    if hparams.use_lws:  #lws：根据幅度频谱恢复数字信号的方法\n",
    "        return _lws_processor(hparams).stft(y).T\n",
    "    else:\n",
    "        return librosa.stft(y=y, n_fft=hparams.n_fft, hop_length=get_hop_size(hparams), win_length=hparams.win_size, pad_mode='constant')\n",
    "\n",
    "def _istft(y, hparams):\n",
    "    return librosa.istft(y, hop_length=get_hop_size(hparams), win_length=hparams.win_size)\n",
    "\n",
    "##########################################################\n",
    "#Those are only correct when using lws!!! (This was messing with Wavenet quality for a long time!)\n",
    "def num_frames(length, fsize, fshift):\n",
    "\t\"\"\"Compute number of time frames of spectrogram\n",
    "\t\"\"\"\n",
    "\tpad = (fsize - fshift)\n",
    "\tif length % fshift == 0:\n",
    "\t\tM = (length + pad * 2 - fsize) // fshift + 1\n",
    "\telse:\n",
    "\t\tM = (length + pad * 2 - fsize) // fshift + 2\n",
    "\treturn M\n",
    "\n",
    "\n",
    "def pad_lr(x, fsize, fshift):\n",
    "\t\"\"\"Compute left and right padding\n",
    "\t\"\"\"\n",
    "\tM = num_frames(len(x), fsize, fshift)\n",
    "\tpad = (fsize - fshift)\n",
    "\tT = len(x) + 2 * pad\n",
    "\tr = (M - 1) * fshift + fsize - T\n",
    "\treturn pad, pad + r\n",
    "##########################################################\n",
    "#Librosa correct padding\n",
    "def librosa_pad_lr(x, fsize, fshift, pad_sides=1):\n",
    "\t'''compute right padding (final frame) or both sides padding (first and final frames)\n",
    "\t'''\n",
    "\tassert pad_sides in (1, 2)\n",
    "\t# return int(fsize // 2)\n",
    "\tpad = (x.shape[0] // fshift + 1) * fshift - x.shape[0]\n",
    "\tif pad_sides == 1:\n",
    "\t\treturn 0, pad\n",
    "\telse:\n",
    "\t\treturn pad // 2, pad // 2 + pad % 2\n",
    "\n",
    "# Conversions\n",
    "_mel_basis = None\n",
    "_inv_mel_basis = None\n",
    "\n",
    "def _linear_to_mel(spectogram, hparams):\n",
    "    global _mel_basis\n",
    "    if _mel_basis is None:\n",
    "        _mel_basis = _build_mel_basis(hparams)\n",
    "    return np.dot(_mel_basis, spectogram)\n",
    "\n",
    "def _mel_to_linear(mel_spectrogram, hparams):\n",
    "    global _inv_mel_basis\n",
    "    if _inv_mel_basis is None:\n",
    "        _inv_mel_basis = np.linalg.pinv(_build_mel_basis(hparams))\n",
    "    return np.maximum(1e-10, np.dot(_inv_mel_basis, mel_spectrogram))\n",
    "\n",
    "def _mel_to_linear_tensorflow(mel_spectrogram, hparams):\n",
    "    global _inv_mel_basis\n",
    "    if _inv_mel_basis is None:\n",
    "        _inv_mel_basis = np.linalg.pinv(_build_mel_basis(hparams))\n",
    "    return tf.transpose(tf.maximum(1e-10, tf.matmul(tf.cast(_inv_mel_basis, tf.float32), tf.transpose(mel_spectrogram, [1, 0]))), [1, 0])\n",
    "\n",
    "def _build_mel_basis(hparams):\n",
    "    assert hparams.fmax <= hparams.sample_rate // 2\n",
    "    return librosa.filters.mel(hparams.sample_rate, hparams.n_fft, n_mels=hparams.num_mels,\n",
    "                               fmin=hparams.fmin, fmax=hparams.fmax)\n",
    "\n",
    "def _amp_to_db(x, hparams):\n",
    "    min_level = np.exp(hparams.min_level_db / 20 * np.log(10))\n",
    "    return 20 * np.log10(np.maximum(min_level, x))\n",
    "\n",
    "def _db_to_amp(x):\n",
    "    return np.power(10.0, (x) * 0.05)\n",
    "\n",
    "def _db_to_amp_tensorflow(x):\n",
    "    return tf.pow(tf.ones(tf.shape(x)) * 10.0, x * 0.05)\n",
    "\n",
    "def _normalize(S, hparams):\n",
    "    if hparams.allow_clipping_in_normalization:\n",
    "        if hparams.symmetric_mels:\n",
    "            return np.clip((2 * hparams.max_abs_value) * ((S - hparams.min_level_db) / (-hparams.min_level_db)) - hparams.max_abs_value,\n",
    "             -hparams.max_abs_value, hparams.max_abs_value)\n",
    "        else:\n",
    "            return np.clip(hparams.max_abs_value * ((S - hparams.min_level_db) / (-hparams.min_level_db)), 0, hparams.max_abs_value)\n",
    "\n",
    "\tassert S.max() <= 0 and S.min() - hparams.min_level_db >= 0\n",
    "\tif hparams.symmetric_mels:\n",
    "\t\treturn (2 * hparams.max_abs_value) * ((S - hparams.min_level_db) / (-hparams.min_level_db)) - hparams.max_abs_value\n",
    "\telse:\n",
    "\t\treturn hparams.max_abs_value * ((S - hparams.min_level_db) / (-hparams.min_level_db))\n",
    "\n",
    "def _denormalize(D, hparams):\n",
    "\tif hparams.allow_clipping_in_normalization:\n",
    "\t\tif hparams.symmetric_mels:\n",
    "\t\t\treturn (((np.clip(D, -hparams.max_abs_value,\n",
    "\t\t\t\thparams.max_abs_value) + hparams.max_abs_value) * -hparams.min_level_db / (2 * hparams.max_abs_value))\n",
    "\t\t\t\t+ hparams.min_level_db)\n",
    "\t\telse:\n",
    "\t\t\treturn ((np.clip(D, 0, hparams.max_abs_value) * -hparams.min_level_db / hparams.max_abs_value) + hparams.min_level_db)\n",
    "\n",
    "\tif hparams.symmetric_mels:\n",
    "\t\treturn (((D + hparams.max_abs_value) * -hparams.min_level_db / (2 * hparams.max_abs_value)) + hparams.min_level_db)\n",
    "\telse:\n",
    "\t\treturn ((D * -hparams.min_level_db / hparams.max_abs_value) + hparams.min_level_db)\n",
    "\n",
    "def _denormalize_tensorflow(D, hparams):\n",
    "\tif hparams.allow_clipping_in_normalization:\n",
    "\t\tif hparams.symmetric_mels:\n",
    "\t\t\treturn (((tf.clip_by_value(D, -hparams.max_abs_value,\n",
    "\t\t\t\thparams.max_abs_value) + hparams.max_abs_value) * -hparams.min_level_db / (2 * hparams.max_abs_value))\n",
    "\t\t\t\t+ hparams.min_level_db)\n",
    "\t\telse:\n",
    "\t\t\treturn ((tf.clip_by_value(D, 0, hparams.max_abs_value) * -hparams.min_level_db / hparams.max_abs_value) + hparams.min_level_db)\n",
    "\n",
    "\tif hparams.symmetric_mels:\n",
    "\t\treturn (((D + hparams.max_abs_value) * -hparams.min_level_db / (2 * hparams.max_abs_value)) + hparams.min_level_db)\n",
    "\telse:\n",
    "\t\treturn ((D * -hparams.min_level_db / hparams.max_abs_value) + hparams.min_level_db)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
