{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460d0c0d-8848-48bc-b385-da62ae45e077",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tacotron.utils.symbols import symbols\n",
    "from infolog import log\n",
    "from tacotron.models.helpers import TacoTrainingHelper, TacoTestHelper\n",
    "from tacotron.models.modules import *\n",
    "from tensorflow.contrib.seq2seq import dynamic_decode\n",
    "from tacotron.models.Architecture_wrappers import TacotronEncoderCell, TacotronDecoderCell\n",
    "from tacotron.models.custom_decoder import CustomDecoder\n",
    "from tacotron.models.attention import \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def split_func(x, split_pos):\n",
    "    rst = []\n",
    "    start = 0\n",
    "    # x will be a numpy array with the contents of the placeholder below\n",
    "    for i in range(split_pos.shape[0]):\n",
    "        rst.append(x[:,start:start+split_pos[i]])\n",
    "        start += split_pos[i]\n",
    "    return rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc7c1c5-0a9c-4724-877a-1186c06e26b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tacotron():\n",
    "    \"\"\"Tacotron-2 Feature prediction Model.\n",
    "    \"\"\"\n",
    "    def __init__(self, hparams):\n",
    "        self._hparams = hparams\n",
    "\n",
    "    def initialize(self, inputs, input_lengths, mel_targets=None, stop_token_targets=None, linear_targets=None, targets_lengths=None, gta=False,\n",
    "            global_step=None, is_training=False, is_evaluating=False, split_infos=None):\n",
    "        \"\"\"\n",
    "        Initializes the model for inference\n",
    "        sets \"mel_outputs\" and \"alignments\" fields.\n",
    "        Args:\n",
    "            - inputs: int32 Tensor with shape [N, T_in] where N is batch size, T_in is number of\n",
    "              steps in the input time series, and values are character IDs\n",
    "            - input_lengths: int32 Tensor with shape [N] where N is batch size and values are the lengths\n",
    "            of each sequence in inputs.\n",
    "            - mel_targets: float32 Tensor with shape [N, T_out, M] where N is batch size, T_out is number\n",
    "            of steps in the output time series, M is num_mels, and values are entries in the mel\n",
    "            spectrogram. Only needed for training.\n",
    "        \"\"\"\n",
    "        if mel_targets is None and stop_token_targets is not None:\n",
    "            raise ValueError('no multi targets were provided but token_targets were given')\n",
    "        if mel_targets is not None and stop_token_targets is None and not gta:\n",
    "            raise ValueError('Mel targets are provided without corresponding token_targets')\n",
    "        if not gta and self._hparams.predict_linear==True and linear_targets is None and is_training:\n",
    "            raise ValueError('Model is set to use post processing to predict linear spectrograms in training but no linear targets given!')\n",
    "        if gta and linear_targets is not None:\n",
    "            raise ValueError('Linear spectrogram prediction is not supported in GTA mode!')\n",
    "        if is_training and self._hparams.mask_decoder and targets_lengths is None:\n",
    "            raise RuntimeError('Model set to mask paddings but no targets lengths provided for the mask!')\n",
    "        if is_training and is_evaluating:\n",
    "            raise RuntimeError('Model can not be in training and evaluation modes at the same time!')\n",
    "            \n",
    "        split_device = '/cpu:0' if self._hparams.tacotron_num_gpus > 1 or self._hparams.split_on_cpu else '/gpu:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc718a5-362f-47a6-b069-00b76265445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "        with tf.device(split_device):\n",
    "            hp = self._hparams\n",
    "            lout_int = [tf.int32]*hp.tacotron_num_gpus\n",
    "            lout_float = [tf.float32]*hp.tacotron_num_gpus\n",
    "\n",
    "            tower_input_lengths = tf.split(input_lengths, num_or_size_splits=hp.tacotron_num_gpus, axis=0)\n",
    "            tower_targets_lengths = tf.split(targets_lengths, num_or_size_splits=hp.tacotron_num_gpus, axis=0) if targets_lengths is not None else targets_lengths\n",
    "\n",
    "            p_inputs = tf.py_func(split_func, [inputs, split_infos[:, 0]], lout_int)\n",
    "            p_mel_targets = tf.py_func(split_func, [mel_targets, split_infos[:,1]], lout_float) if mel_targets is not None else mel_targets\n",
    "            p_stop_token_targets = tf.py_func(split_func, [stop_token_targets, split_infos[:,2]], lout_float) if stop_token_targets is not None else stop_token_targets\n",
    "            p_linear_targets = tf.py_func(split_func, [linear_targets, split_infos[:,3]], lout_float) if linear_targets is not None else linear_targets\n",
    "\n",
    "            tower_inputs = []\n",
    "            tower_mel_targets = []\n",
    "            tower_stop_token_targets = []\n",
    "            tower_linear_targets = []\n",
    "\n",
    "            batch_size = tf.shape(inputs)[0]\n",
    "            mel_channels = hp.num_mels\n",
    "            linear_channels = hp.num_freq\n",
    "            for i in range (hp.tacotron_num_gpus):\n",
    "                tower_inputs.append(tf.reshape(p_inputs[i], [batch_size, -1]))\n",
    "                if p_mel_targets is not None:\n",
    "                    tower_mel_targets.append(tf.reshape(p_mel_targets[i], [batch_size, -1, mel_channels]))\n",
    "                if p_stop_token_targets is not None:\n",
    "                    tower_stop_token_targets.append(tf.reshape(p_stop_token_targets[i], [batch_size, -1]))\n",
    "                if p_linear_targets is not None:\n",
    "                    tower_linear_targets.append(tf.reshape(p_linear_targets[i], [batch_size, -1, linear_channels]))\n",
    "\n",
    "        T2_output_range = (-hp.max_abs_value, hp.max_abs_value) if hp.symmetric_mels else (0, hp.max_abs_value)\n",
    "\n",
    "        self.tower_decoder_output = []\n",
    "        self.tower_alignments = []\n",
    "        self.tower_stop_token_prediction = []\n",
    "        self.tower_mel_outputs = []\n",
    "        self.tower_linear_outputs = []\n",
    "\n",
    "        tower_embedded_inputs = []\n",
    "        tower_enc_conv_output_shape = []\n",
    "        tower_encoder_outputs = []\n",
    "        tower_residual = []\n",
    "        tower_projected_residual = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93ffc6a-02ab-4372-a72a-605ed97b065e",
   "metadata": {},
   "source": [
    "### tf.py_func\n",
    "\n",
    "这是一个可以把 TensorFlow 和 Python 原生代码无缝衔接起来的函数，有了它，你就可以在 TensorFlow 里面自由的实现你想要的功能，而不用考虑 TensorFlow 有没有实现它的 API，并且可以帮助我们实现自由的检查该功能模块的输入输出是否正确，而不受到TensorFlow 的先构造计算图再运行导致的不能单独检测单一模块的功能的限制；\n",
    "\n",
    "它的具体功能描述是**包装一个普通的 Python 函数，这个函数接受 numpy 的数组作为输入和输出，让这个函数可以作为 TensorFlow 计算图上的计算节点 OP 来使用**。\n",
    "\n",
    "```\n",
    "py_func(func, inp, Tout, stateful=True, name=None)\n",
    "```\n",
    "\n",
    "参数：\n",
    "\n",
    "- 一个 Python 函数, 它接受 NumPy 数组作为输入和输出，并且数组的类型和大小必须和输入和输出用来衔接的 Tensor 大小和数据类型相匹配.\n",
    "\n",
    "- inp: 输入的 Tensor 列表.\n",
    "\n",
    "- Tout: 输出 Tensor 数据类型的列表或元祖.\n",
    "\n",
    "- stateful: boolean\n",
    "\n",
    "- name: 节点op的名称\n",
    "\n",
    "**缺点：**\n",
    "\n",
    "这个被包装过的的计算函数的内部部分不会被序列化到 GraphDef 里面去，所以，如果你要序列化存储和恢复模型，就不能使用该函数。\n",
    "这个被包装的计算节点 OP 与调用它的 Python 程序必须运行在同一个物理设备上，也就是说，如果使用分布式TensorFlow，必须使用 tf.train.Server 和 with tf.device(): 来保证二者在同一个服务器内。\n",
    "\n",
    "```\n",
    "import tensorflow as tf\n",
    "\n",
    "def add(x,y):\n",
    "     return x+y,x-y,x.dot(y)\n",
    "\n",
    "a = [[1,2],[3,4]]\n",
    "b = [[1,2],[1,1]]\n",
    "x = tf.placeholder(tf.float32,(2,2))\n",
    "y = tf.placeholder(tf.float32,(2,2))\n",
    "result1,result2,result3 = tf.py_func(add, [x,y], [tf.float32,tf.float32,tf.float32])\n",
    "\n",
    "with tf.Session as sess:\n",
    "    sess.run(tf.global_varbles_initializer())\n",
    "    s1,s2,s3 = sess.run([result1,result2,result3],feed_dict = {x:a,y:b})\n",
    "    print(s1,s2,s3)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bc4c27-f6b7-43ca-9ef8-d6b31b532165",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # 1. Declare GPU Devices\n",
    "        gpus = [f\"/gpu:{i}\" for i in range(hp.tacotron_num_gpus)]\n",
    "        for i in range(hp.tacotron_num_gpus):\n",
    "            with tf.device(tf.train.replica_device_setter(ps_tasks=1, ps_device=\"/cpu:0\", worker_device=gpus[i])):\n",
    "                with tf.variable_scope('inference') as scope:\n",
    "                    assert hp.tacotron_teacher_forcing_mode in ('constant', 'scheduled')\n",
    "                    if hp.tacotron_teacher_forcing_mode == 'scheduled' and is_training:\n",
    "                        assert global_step is not None\n",
    "\n",
    "                    #GTA is only used for predicting mels to train Wavenet vocoder, so we ommit post processing when doing GTA synthesis\n",
    "                    post_condition = hp.predict_linear and not gta\n",
    "\n",
    "                    # Embeddings ==> [batch_size, sequence_length, embedding_dim]\n",
    "                    self.embedding_table = tf.get_variable('inputs_embedding', [len(symbols), hp.embedding_dim], dtype=tf.float32)\n",
    "                    embedded_inputs = tf.nn.embedding_lookup(self.embedding_table, tower_inputs[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38031b55-cedc-4f94-8dbb-2d4c11dc7090",
   "metadata": {},
   "source": [
    "### Encoder\n",
    "\n",
    "Encoder部分是由TacotronEncoderCell类表示的，里面包含了EncoderConvolutions卷积和 EncoderRNN(lstm)循环网络，TacotronEncoderCell在`./Architecture_wrapper.ipynb`中。EncoderConvolutions和EncoderRNN在`./modules.ipynb`\n",
    "\n",
    "具体内容看 ：\n",
    "\n",
    "- `./Architecture_wrappers.ipynb` http://localhost:8888/lab/tree/TTS/Speech-Zone/Tacotron2/Tacotron2/tacotron/models/Architecture_wrappers.ipynb\n",
    "\n",
    "-  `./modules.ipynb` http://localhost:8888/lab/tree/TTS/Speech-Zone/Tacotron2/Tacotron2/tacotron/models/modules.ipynb\n",
    "\n",
    "Passes inputs through a stack of convolutional layers (3 layers, kernel_size=5, channel=512, dropout_rate=0.5, relu,在激活函数之后用batch_norm) then through a bidirectional LSTM layer(zoneout instead of dropout) to predict the hidden representation vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bd9e5e-eb86-4361-97fa-c34b61069eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "                    #Encoder Cell ==> [batch_size, encoder_steps, encoder_lstm_units]\n",
    "                    encoder_cell = TacotronEncoderCell(\n",
    "                        EncoderConvolutions(is_training, hparams=hp, scope='encoder_convolutions'),\n",
    "                        EncoderRNN(is_training, size=hp.encoder_lstm_units,\n",
    "                            zoneout=hp.tacotron_zoneout_rate, scope='encoder_LSTM'))\n",
    "\n",
    "                    encoder_outputs = encoder_cell(embedded_inputs, tower_input_lengths[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a676a42-2d15-46dd-b35d-4e1dc70ca544",
   "metadata": {},
   "source": [
    "### Decoder\n",
    "\n",
    "Decoder部分由Prenet, attention, lstm, frame_projection 和 stop_projection 组成。\n",
    "\n",
    "具体内容看： \n",
    "\n",
    "- prenet: 两个全连接层，dropout_rate=0.5, layers_sizes=[256, 256], activate_func=relu \n",
    "            \n",
    "    - `./modules.ipynb` http://localhost:8888/lab/tree/TTS/Speech-Zone/Tacotron2/Tacotron2/tacotron/models/modules.ipynb\n",
    "\n",
    "- attention:\n",
    "    \n",
    "    - `./models/attention.ipynb` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0046f73-093e-4efb-9547-fbe1a363c841",
   "metadata": {},
   "outputs": [],
   "source": [
    "                    #Decoder Parts\n",
    "                    #Attention Decoder Prenet\n",
    "                    prenet = Prenet(is_training, layers_sizes=hp.prenet_layers, drop_rate=hp.tacotron_dropout_rate, scope='decoder_prenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfaf428-8ea4-43fc-9515-d497ddf9cb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "                    attention_mechanism = LocationSensitiveAttention(hp.attention_dim, encoder_outputs, hparams=hp, is_training=is_training,\n",
    "                                                                     mask_encoder=hp.mask_encoder, memory_sequence_length=tf.reshape(tower_input_lengths[i], [-1]), \n",
    "                                                                     smoothing=hp.smoothing, cumulate_weights=hp.cumulative_weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
